{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CNN_LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"haXfHHQJIfXR","colab_type":"code","outputId":"1c94a278-fa9e-4e9b-f1de-74ecaa735b0c","executionInfo":{"status":"ok","timestamp":1557917539177,"user_tz":-120,"elapsed":2770,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"WoANn0IpIo-K","colab_type":"code","outputId":"0e5bad22-45b4-4cde-a9a3-12c5aa954c5a","executionInfo":{"status":"ok","timestamp":1557917542954,"user_tz":-120,"elapsed":6516,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BhJGRlbItt9","colab_type":"code","outputId":"c29c4ef2-aad1-4e8c-adb6-176972ed875f","executionInfo":{"status":"ok","timestamp":1557917542959,"user_tz":-120,"elapsed":6500,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":198}},"source":["import pandas as pd\n","Data =  pd.read_json('/content/drive/My Drive/Sarcasm Detection/Arabic News Headlines Dataset.json', orient = 'split')\n","Data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>topic</th>\n","      <th>length</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...</td>\n","      <td>Society</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...</td>\n","      <td>Sports</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...</td>\n","      <td>Misc</td>\n","      <td>17</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...</td>\n","      <td>None</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...</td>\n","      <td>Misc</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           headlines  ... is_sarcastic\n","0  طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...  ...            1\n","1  سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...  ...            0\n","2  ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...  ...            1\n","3  وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...  ...            0\n","4  ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...  ...            1\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"eZfh50WcKc8j","colab_type":"code","colab":{}},"source":["X = Data['headlines']\n","Labels = Data['is_sarcastic']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGE1RQHEK5KP","colab_type":"code","outputId":"060b5333-3137-494f-d2c1-6ba629bf4bd9","executionInfo":{"status":"ok","timestamp":1557917542965,"user_tz":-120,"elapsed":6482,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","max_sequence_length = np.max(Data['length'])\n","print(\"max length is:\", max_sequence_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["max length is: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pIh6s6cxJB02","colab_type":"code","outputId":"1e506baf-33f3-406d-84f6-60dcdd71c8d2","executionInfo":{"status":"ok","timestamp":1557917542966,"user_tz":-120,"elapsed":6467,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import keras\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=30000)\n","tokenizer.fit_on_texts(X)\n","sequences = tokenizer.texts_to_sequences(X)\n","\n","word_index = tokenizer.word_index   # a dictionary of each word and its index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 20595 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"enlqxEX4KZY0","colab_type":"code","outputId":"e217b3b7-b816-49bf-f30b-cdee68119ecd","executionInfo":{"status":"ok","timestamp":1557917542968,"user_tz":-120,"elapsed":6445,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.preprocessing.sequence import pad_sequences\n","data = pad_sequences(sequences, maxlen=max_sequence_length)\n","print('Shape of data tensor:', data.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of data tensor: (6669, 34)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dYo4nQrLVVj","colab_type":"code","outputId":"57479ef4-bdf6-45ec-ed85-560b4b2eb4df","executionInfo":{"status":"ok","timestamp":1557917542969,"user_tz":-120,"elapsed":6428,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.utils import to_categorical\n","labels = to_categorical(np.asarray(Labels))  ## one hot of the output\n","print('Shape of label tensor:', labels.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (6669, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4r21pAbOLz0w","colab_type":"code","colab":{}},"source":["import pickle as p\n","fastText = p.load(open('/content/drive/My Drive/Sarcasm Detection/FastText_Wiki_Embeddings.p', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxwadMk9MHir","colab_type":"code","outputId":"82350cca-98cd-4154-cc84-17344be3144f","executionInfo":{"status":"ok","timestamp":1557917546918,"user_tz":-120,"elapsed":10334,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# prepare embedding matrix  (matrix of embeddings of the words in our dataset)\n","num_words = len(word_index) + 1\n","# initialize the np array\n","unKnown = list()\n","embedding_matrix = np.zeros((num_words, 300))\n","l=0\n","# find the embeddings from the pre trained embedding matrix of fast text wiki\n","for word, i in word_index.items():\n","    embedding_vector = fastText.get(word)\n","    if embedding_vector is not None:\n","        l+=1\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","      unKnown.append(word)\n","print(\"the number of words found in fast text embeddings =\", l)\n","print(\"the number of words not found in fast text embeddings =\", 20595- l)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["the number of words found in fast text embeddings = 17289\n","the number of words not found in fast text embeddings = 3306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpFKygkfMdYG","colab_type":"code","colab":{}},"source":["from keras.initializers import Constant\n","from keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling2D, Dense, Dropout, LSTM\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahqU4hM6Mj1F","colab_type":"code","colab":{}},"source":["# shuffle the data\n","\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","## split the data into training, testing\n","\n","nb_validation_samples = int(0.25* data.shape[0])\n","\n","x_train = data[:-nb_validation_samples]\n","y_train = labels[:-nb_validation_samples]\n","x_test = data[-nb_validation_samples:]\n","y_test = labels[-nb_validation_samples:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7FbLoXSM5O7","colab_type":"code","colab":{}},"source":["embedding_layer = Embedding(num_words,\n","                            300,\n","                            embeddings_initializer=Constant(embedding_matrix),\n","                            input_length=max_sequence_length,\n","                            trainable=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVPVJUeoNNJv","colab_type":"code","colab":{}},"source":["# the model\n","\n","sequence_input = Input(shape=(max_sequence_length,), dtype='int32')             ## input layer\n","embedded_sequences = embedding_layer(sequence_input)                            ## embeddings layer\n","X = Conv1D(300, 3, activation='relu')(embedded_sequences)                       ## CNN layer\n","X = Conv1D(300, 3, activation='relu')(X)                                        ## CNN layer\n","X = LSTM(300, return_sequences=True)(X)                                         ## LSTM layer\n","X = Dropout(0.5)(X)                                                             ## Dropout layer\n","X = LSTM(300, return_sequences=False)(X)                                        ## LSTM layer\n","X = Dropout(0.5)(X)                                                             ## Dropout layer\n","X = Dense(300, activation = \"sigmoid\")(X)                                       ## Fully Connected\n","preds = Dense(2, activation='softmax')(X)                                       ## softmax layer\n","\n","model = Model(sequence_input, preds)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9GoXWQHGlrV","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","\n","def recall(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","\n","      \n","def precision(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","      \n","\n","def f1(y_true, y_pred):\n","    \n","    Precision = precision(y_true, y_pred)\n","    Recall = recall(y_true, y_pred)\n","    f1 = 2*((Precision*Recall)/(Precision+Recall+K.epsilon()))\n","    \n","    return f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lz9NTzDpF-S0","colab_type":"code","colab":{}},"source":["adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.3, amsgrad=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0D3q-GUXGjhG","colab_type":"code","outputId":"ad05dbd4-0acd-40ea-c34f-ec73eb768e61","executionInfo":{"status":"ok","timestamp":1557918148464,"user_tz":-120,"elapsed":611845,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":1983}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.4948 - acc: 0.7436 - val_loss: 0.3425 - val_acc: 0.8482\n","Epoch 2/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.3128 - acc: 0.8605 - val_loss: 0.3014 - val_acc: 0.8761\n","Epoch 3/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2823 - acc: 0.8788 - val_loss: 0.2837 - val_acc: 0.8841\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2655 - acc: 0.8920 - val_loss: 0.2728 - val_acc: 0.8851\n","Epoch 5/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2524 - acc: 0.8963 - val_loss: 0.2669 - val_acc: 0.8861\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2434 - acc: 0.8983 - val_loss: 0.2627 - val_acc: 0.8821\n","Epoch 7/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2368 - acc: 0.9020 - val_loss: 0.2594 - val_acc: 0.8821\n","Epoch 8/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2301 - acc: 0.9058 - val_loss: 0.2571 - val_acc: 0.8811\n","Epoch 9/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2267 - acc: 0.9080 - val_loss: 0.2564 - val_acc: 0.8851\n","Epoch 10/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2230 - acc: 0.9100 - val_loss: 0.2546 - val_acc: 0.8831\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2197 - acc: 0.9103 - val_loss: 0.2533 - val_acc: 0.8801\n","Epoch 12/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2185 - acc: 0.9113 - val_loss: 0.2529 - val_acc: 0.8861\n","Epoch 13/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2143 - acc: 0.9133 - val_loss: 0.2521 - val_acc: 0.8831\n","Epoch 14/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2135 - acc: 0.9138 - val_loss: 0.2519 - val_acc: 0.8881\n","Epoch 15/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2109 - acc: 0.9140 - val_loss: 0.2512 - val_acc: 0.8831\n","Epoch 16/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2088 - acc: 0.9155 - val_loss: 0.2509 - val_acc: 0.8881\n","Epoch 17/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2082 - acc: 0.9168 - val_loss: 0.2508 - val_acc: 0.8841\n","Epoch 18/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2060 - acc: 0.9160 - val_loss: 0.2502 - val_acc: 0.8831\n","Epoch 19/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2037 - acc: 0.9168 - val_loss: 0.2500 - val_acc: 0.8831\n","Epoch 20/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2039 - acc: 0.9158 - val_loss: 0.2498 - val_acc: 0.8841\n","Epoch 21/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2012 - acc: 0.9165 - val_loss: 0.2496 - val_acc: 0.8821\n","Epoch 22/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1995 - acc: 0.9188 - val_loss: 0.2495 - val_acc: 0.8841\n","Epoch 23/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1995 - acc: 0.9190 - val_loss: 0.2492 - val_acc: 0.8821\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1979 - acc: 0.9190 - val_loss: 0.2492 - val_acc: 0.8841\n","Epoch 25/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1970 - acc: 0.9198 - val_loss: 0.2491 - val_acc: 0.8851\n","Epoch 26/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1959 - acc: 0.9193 - val_loss: 0.2489 - val_acc: 0.8851\n","Epoch 27/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1943 - acc: 0.9205 - val_loss: 0.2490 - val_acc: 0.8851\n","Epoch 28/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1943 - acc: 0.9213 - val_loss: 0.2486 - val_acc: 0.8841\n","Epoch 29/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1923 - acc: 0.9228 - val_loss: 0.2486 - val_acc: 0.8841\n","Epoch 30/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1926 - acc: 0.9203 - val_loss: 0.2485 - val_acc: 0.8851\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1910 - acc: 0.9208 - val_loss: 0.2484 - val_acc: 0.8851\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1903 - acc: 0.9228 - val_loss: 0.2484 - val_acc: 0.8861\n","Epoch 33/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1895 - acc: 0.9225 - val_loss: 0.2487 - val_acc: 0.8881\n","Epoch 34/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1895 - acc: 0.9223 - val_loss: 0.2484 - val_acc: 0.8871\n","Epoch 35/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1881 - acc: 0.9238 - val_loss: 0.2485 - val_acc: 0.8871\n","Epoch 36/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1872 - acc: 0.9235 - val_loss: 0.2483 - val_acc: 0.8871\n","Epoch 37/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1873 - acc: 0.9233 - val_loss: 0.2483 - val_acc: 0.8871\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1858 - acc: 0.9238 - val_loss: 0.2483 - val_acc: 0.8871\n","Epoch 39/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1862 - acc: 0.9248 - val_loss: 0.2481 - val_acc: 0.8861\n","Epoch 40/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1855 - acc: 0.9240 - val_loss: 0.2483 - val_acc: 0.8851\n","Epoch 41/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1844 - acc: 0.9250 - val_loss: 0.2480 - val_acc: 0.8861\n","Epoch 42/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1848 - acc: 0.9240 - val_loss: 0.2481 - val_acc: 0.8861\n","Epoch 43/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1835 - acc: 0.9248 - val_loss: 0.2480 - val_acc: 0.8851\n","Epoch 44/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1832 - acc: 0.9253 - val_loss: 0.2480 - val_acc: 0.8851\n","Epoch 45/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1827 - acc: 0.9248 - val_loss: 0.2481 - val_acc: 0.8861\n","Epoch 46/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1820 - acc: 0.9268 - val_loss: 0.2483 - val_acc: 0.8861\n","Epoch 47/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1813 - acc: 0.9253 - val_loss: 0.2481 - val_acc: 0.8851\n","Epoch 48/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1813 - acc: 0.9263 - val_loss: 0.2478 - val_acc: 0.8891\n","Epoch 49/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1800 - acc: 0.9250 - val_loss: 0.2478 - val_acc: 0.8861\n","Epoch 50/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1807 - acc: 0.9260 - val_loss: 0.2476 - val_acc: 0.8881\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2659947186905106\n","test accuracy is:  0.8914217156568687\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ONHtOUAMGkGO","colab_type":"code","outputId":"4f3445e3-72a3-47df-8abd-4314dcc1ebce","executionInfo":{"status":"ok","timestamp":1557920448195,"user_tz":-120,"elapsed":604198,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":1908}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.4684 - precision: 0.7546 - val_loss: 0.3337 - val_precision: 0.8541\n","Epoch 2/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.3074 - precision: 0.8643 - val_loss: 0.2978 - val_precision: 0.8741\n","Epoch 3/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2763 - precision: 0.8808 - val_loss: 0.2837 - val_precision: 0.8791\n","Epoch 4/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2580 - precision: 0.8938 - val_loss: 0.2740 - val_precision: 0.8831\n","Epoch 5/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2450 - precision: 0.8988 - val_loss: 0.2677 - val_precision: 0.8821\n","Epoch 6/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2391 - precision: 0.9025 - val_loss: 0.2620 - val_precision: 0.8841\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2311 - precision: 0.9083 - val_loss: 0.2592 - val_precision: 0.8851\n","Epoch 8/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2264 - precision: 0.9088 - val_loss: 0.2580 - val_precision: 0.8851\n","Epoch 9/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2215 - precision: 0.9118 - val_loss: 0.2567 - val_precision: 0.8821\n","Epoch 10/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2190 - precision: 0.9130 - val_loss: 0.2527 - val_precision: 0.8861\n","Epoch 11/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2159 - precision: 0.9153 - val_loss: 0.2516 - val_precision: 0.8871\n","Epoch 12/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2113 - precision: 0.9148 - val_loss: 0.2508 - val_precision: 0.8891\n","Epoch 13/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2092 - precision: 0.9165 - val_loss: 0.2497 - val_precision: 0.8861\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2072 - precision: 0.9178 - val_loss: 0.2493 - val_precision: 0.8871\n","Epoch 15/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2046 - precision: 0.9213 - val_loss: 0.2485 - val_precision: 0.8861\n","Epoch 16/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2031 - precision: 0.9193 - val_loss: 0.2480 - val_precision: 0.8881\n","Epoch 17/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2001 - precision: 0.9205 - val_loss: 0.2472 - val_precision: 0.8881\n","Epoch 18/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1981 - precision: 0.9213 - val_loss: 0.2470 - val_precision: 0.8881\n","Epoch 19/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1974 - precision: 0.9235 - val_loss: 0.2469 - val_precision: 0.8861\n","Epoch 20/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1957 - precision: 0.9243 - val_loss: 0.2465 - val_precision: 0.8881\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1953 - precision: 0.9223 - val_loss: 0.2468 - val_precision: 0.8861\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1931 - precision: 0.9260 - val_loss: 0.2462 - val_precision: 0.8871\n","Epoch 23/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1919 - precision: 0.9270 - val_loss: 0.2460 - val_precision: 0.8881\n","Epoch 24/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1911 - precision: 0.9278 - val_loss: 0.2460 - val_precision: 0.8871\n","Epoch 25/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1884 - precision: 0.9295 - val_loss: 0.2458 - val_precision: 0.8871\n","Epoch 26/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1903 - precision: 0.9278 - val_loss: 0.2455 - val_precision: 0.8851\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1886 - precision: 0.9273 - val_loss: 0.2456 - val_precision: 0.8861\n","Epoch 28/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1867 - precision: 0.9288 - val_loss: 0.2455 - val_precision: 0.8861\n","Epoch 29/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1852 - precision: 0.9313 - val_loss: 0.2447 - val_precision: 0.8891\n","Epoch 30/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1867 - precision: 0.9290 - val_loss: 0.2449 - val_precision: 0.8881\n","Epoch 31/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1842 - precision: 0.9298 - val_loss: 0.2449 - val_precision: 0.8851\n","Epoch 32/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1845 - precision: 0.9300 - val_loss: 0.2445 - val_precision: 0.8901\n","Epoch 33/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1823 - precision: 0.9303 - val_loss: 0.2448 - val_precision: 0.8871\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1817 - precision: 0.9330 - val_loss: 0.2449 - val_precision: 0.8881\n","Epoch 35/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1808 - precision: 0.9318 - val_loss: 0.2442 - val_precision: 0.8921\n","Epoch 36/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1799 - precision: 0.9320 - val_loss: 0.2441 - val_precision: 0.8911\n","Epoch 37/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1800 - precision: 0.9318 - val_loss: 0.2443 - val_precision: 0.8911\n","Epoch 38/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1789 - precision: 0.9333 - val_loss: 0.2443 - val_precision: 0.8911\n","Epoch 39/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1780 - precision: 0.9323 - val_loss: 0.2448 - val_precision: 0.8871\n","Epoch 40/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1766 - precision: 0.9330 - val_loss: 0.2448 - val_precision: 0.8871\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1779 - precision: 0.9333 - val_loss: 0.2442 - val_precision: 0.8921\n","Epoch 42/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1784 - precision: 0.9335 - val_loss: 0.2441 - val_precision: 0.8921\n","Epoch 43/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1749 - precision: 0.9333 - val_loss: 0.2442 - val_precision: 0.8911\n","Epoch 44/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1751 - precision: 0.9350 - val_loss: 0.2442 - val_precision: 0.8911\n","Epoch 45/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1750 - precision: 0.9340 - val_loss: 0.2440 - val_precision: 0.8921\n","Epoch 46/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1736 - precision: 0.9340 - val_loss: 0.2439 - val_precision: 0.8921\n","Epoch 47/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1743 - precision: 0.9330 - val_loss: 0.2439 - val_precision: 0.8921\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1721 - precision: 0.9340 - val_loss: 0.2439 - val_precision: 0.8921\n","Epoch 49/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1734 - precision: 0.9343 - val_loss: 0.2440 - val_precision: 0.8911\n","Epoch 50/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1712 - precision: 0.9378 - val_loss: 0.2439 - val_precision: 0.8931\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2821272115240429\n","test accuracy is:  0.883623275344931\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C8PmQluXGkmb","colab_type":"code","outputId":"cc438e70-8aeb-43b0-fc3c-166afa101376","executionInfo":{"status":"ok","timestamp":1557922708143,"user_tz":-120,"elapsed":43402,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":1908}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.4925 - recall: 0.7571 - val_loss: 0.3691 - val_recall: 0.8332\n","Epoch 2/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.3261 - recall: 0.8510 - val_loss: 0.3265 - val_recall: 0.8521\n","Epoch 3/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2910 - recall: 0.8743 - val_loss: 0.3098 - val_recall: 0.8631\n","Epoch 4/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2722 - recall: 0.8840 - val_loss: 0.2999 - val_recall: 0.8661\n","Epoch 5/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2627 - recall: 0.8923 - val_loss: 0.2952 - val_recall: 0.8691\n","Epoch 6/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2532 - recall: 0.8943 - val_loss: 0.2921 - val_recall: 0.8701\n","Epoch 7/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2471 - recall: 0.8975 - val_loss: 0.2874 - val_recall: 0.8731\n","Epoch 8/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2409 - recall: 0.9028 - val_loss: 0.2849 - val_recall: 0.8751\n","Epoch 9/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2374 - recall: 0.9050 - val_loss: 0.2826 - val_recall: 0.8761\n","Epoch 10/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2335 - recall: 0.9083 - val_loss: 0.2815 - val_recall: 0.8781\n","Epoch 11/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2294 - recall: 0.9078 - val_loss: 0.2805 - val_recall: 0.8791\n","Epoch 12/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2276 - recall: 0.9080 - val_loss: 0.2793 - val_recall: 0.8801\n","Epoch 13/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2252 - recall: 0.9108 - val_loss: 0.2794 - val_recall: 0.8771\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2234 - recall: 0.9113 - val_loss: 0.2778 - val_recall: 0.8781\n","Epoch 15/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2204 - recall: 0.9120 - val_loss: 0.2782 - val_recall: 0.8781\n","Epoch 16/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2196 - recall: 0.9103 - val_loss: 0.2782 - val_recall: 0.8781\n","Epoch 17/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2183 - recall: 0.9140 - val_loss: 0.2765 - val_recall: 0.8801\n","Epoch 18/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2161 - recall: 0.9150 - val_loss: 0.2757 - val_recall: 0.8801\n","Epoch 19/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2149 - recall: 0.9145 - val_loss: 0.2753 - val_recall: 0.8811\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2139 - recall: 0.9145 - val_loss: 0.2746 - val_recall: 0.8791\n","Epoch 21/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2131 - recall: 0.9158 - val_loss: 0.2741 - val_recall: 0.8801\n","Epoch 22/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2101 - recall: 0.9168 - val_loss: 0.2739 - val_recall: 0.8811\n","Epoch 23/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2098 - recall: 0.9158 - val_loss: 0.2737 - val_recall: 0.8821\n","Epoch 24/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2096 - recall: 0.9195 - val_loss: 0.2732 - val_recall: 0.8811\n","Epoch 25/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2079 - recall: 0.9173 - val_loss: 0.2742 - val_recall: 0.8801\n","Epoch 26/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2076 - recall: 0.9175 - val_loss: 0.2732 - val_recall: 0.8821\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2068 - recall: 0.9183 - val_loss: 0.2727 - val_recall: 0.8831\n","Epoch 28/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2045 - recall: 0.9200 - val_loss: 0.2724 - val_recall: 0.8831\n","Epoch 29/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2050 - recall: 0.9178 - val_loss: 0.2729 - val_recall: 0.8821\n","Epoch 30/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2045 - recall: 0.9220 - val_loss: 0.2723 - val_recall: 0.8831\n","Epoch 31/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2031 - recall: 0.9210 - val_loss: 0.2722 - val_recall: 0.8831\n","Epoch 32/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2030 - recall: 0.9205 - val_loss: 0.2719 - val_recall: 0.8841\n","Epoch 33/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2010 - recall: 0.9215 - val_loss: 0.2720 - val_recall: 0.8851\n","Epoch 34/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2012 - recall: 0.9218 - val_loss: 0.2716 - val_recall: 0.8841\n","Epoch 35/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2002 - recall: 0.9195 - val_loss: 0.2719 - val_recall: 0.8851\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1989 - recall: 0.9210 - val_loss: 0.2720 - val_recall: 0.8831\n","Epoch 37/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1991 - recall: 0.9210 - val_loss: 0.2715 - val_recall: 0.8841\n","Epoch 38/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1981 - recall: 0.9235 - val_loss: 0.2717 - val_recall: 0.8821\n","Epoch 39/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1965 - recall: 0.9230 - val_loss: 0.2713 - val_recall: 0.8841\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1972 - recall: 0.9238 - val_loss: 0.2713 - val_recall: 0.8841\n","Epoch 41/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1972 - recall: 0.9235 - val_loss: 0.2713 - val_recall: 0.8821\n","Epoch 42/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1968 - recall: 0.9238 - val_loss: 0.2708 - val_recall: 0.8841\n","Epoch 43/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1947 - recall: 0.9250 - val_loss: 0.2713 - val_recall: 0.8831\n","Epoch 44/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1938 - recall: 0.9248 - val_loss: 0.2712 - val_recall: 0.8831\n","Epoch 45/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1947 - recall: 0.9235 - val_loss: 0.2708 - val_recall: 0.8831\n","Epoch 46/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1928 - recall: 0.9250 - val_loss: 0.2708 - val_recall: 0.8831\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1935 - recall: 0.9245 - val_loss: 0.2707 - val_recall: 0.8841\n","Epoch 48/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1929 - recall: 0.9245 - val_loss: 0.2707 - val_recall: 0.8841\n","Epoch 49/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1922 - recall: 0.9253 - val_loss: 0.2709 - val_recall: 0.8841\n","Epoch 50/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1927 - recall: 0.9248 - val_loss: 0.2707 - val_recall: 0.8851\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2867559242868449\n","test accuracy is:  0.8854229154169166\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTPK13hBGlHk","colab_type":"code","outputId":"86703d58-8476-4035-a348-ba4adedee668","colab":{"base_uri":"https://localhost:8080/","height":1908},"executionInfo":{"status":"ok","timestamp":1557922008033,"user_tz":-120,"elapsed":61553,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = adam, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.4322 - f1: 0.7891 - val_loss: 0.3247 - val_f1: 0.8511\n","Epoch 2/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.3028 - f1: 0.8688 - val_loss: 0.2920 - val_f1: 0.8701\n","Epoch 3/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2743 - f1: 0.8855 - val_loss: 0.2791 - val_f1: 0.8761\n","Epoch 4/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2570 - f1: 0.8938 - val_loss: 0.2718 - val_f1: 0.8821\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2471 - f1: 0.9008 - val_loss: 0.2645 - val_f1: 0.8851\n","Epoch 6/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2406 - f1: 0.9025 - val_loss: 0.2608 - val_f1: 0.8851\n","Epoch 7/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2355 - f1: 0.9048 - val_loss: 0.2585 - val_f1: 0.8891\n","Epoch 8/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2306 - f1: 0.9085 - val_loss: 0.2563 - val_f1: 0.8911\n","Epoch 9/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2261 - f1: 0.9098 - val_loss: 0.2566 - val_f1: 0.8871\n","Epoch 10/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2238 - f1: 0.9105 - val_loss: 0.2539 - val_f1: 0.8881\n","Epoch 11/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2205 - f1: 0.9113 - val_loss: 0.2525 - val_f1: 0.8901\n","Epoch 12/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2193 - f1: 0.9133 - val_loss: 0.2514 - val_f1: 0.8901\n","Epoch 13/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2161 - f1: 0.9153 - val_loss: 0.2508 - val_f1: 0.8911\n","Epoch 14/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2146 - f1: 0.9155 - val_loss: 0.2500 - val_f1: 0.8911\n","Epoch 15/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2143 - f1: 0.9143 - val_loss: 0.2495 - val_f1: 0.8931\n","Epoch 16/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2097 - f1: 0.9155 - val_loss: 0.2489 - val_f1: 0.8891\n","Epoch 17/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2079 - f1: 0.9183 - val_loss: 0.2484 - val_f1: 0.8911\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2088 - f1: 0.9165 - val_loss: 0.2482 - val_f1: 0.8891\n","Epoch 19/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2064 - f1: 0.9183 - val_loss: 0.2475 - val_f1: 0.8901\n","Epoch 20/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2044 - f1: 0.9200 - val_loss: 0.2472 - val_f1: 0.8931\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2047 - f1: 0.9188 - val_loss: 0.2470 - val_f1: 0.8921\n","Epoch 22/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2032 - f1: 0.9225 - val_loss: 0.2466 - val_f1: 0.8941\n","Epoch 23/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2013 - f1: 0.9210 - val_loss: 0.2463 - val_f1: 0.8921\n","Epoch 24/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.2012 - f1: 0.9238 - val_loss: 0.2461 - val_f1: 0.8941\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1990 - f1: 0.9215 - val_loss: 0.2465 - val_f1: 0.8911\n","Epoch 26/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1978 - f1: 0.9210 - val_loss: 0.2457 - val_f1: 0.8951\n","Epoch 27/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1975 - f1: 0.9245 - val_loss: 0.2456 - val_f1: 0.8941\n","Epoch 28/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1963 - f1: 0.9235 - val_loss: 0.2458 - val_f1: 0.8951\n","Epoch 29/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1955 - f1: 0.9235 - val_loss: 0.2455 - val_f1: 0.8951\n","Epoch 30/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1951 - f1: 0.9248 - val_loss: 0.2455 - val_f1: 0.8951\n","Epoch 31/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1933 - f1: 0.9243 - val_loss: 0.2455 - val_f1: 0.8961\n","Epoch 32/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1941 - f1: 0.9235 - val_loss: 0.2452 - val_f1: 0.8951\n","Epoch 33/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1916 - f1: 0.9260 - val_loss: 0.2450 - val_f1: 0.8941\n","Epoch 34/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1912 - f1: 0.9253 - val_loss: 0.2449 - val_f1: 0.8941\n","Epoch 35/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1920 - f1: 0.9245 - val_loss: 0.2448 - val_f1: 0.8951\n","Epoch 36/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1922 - f1: 0.9253 - val_loss: 0.2449 - val_f1: 0.8951\n","Epoch 37/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1911 - f1: 0.9243 - val_loss: 0.2447 - val_f1: 0.8951\n","Epoch 38/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1888 - f1: 0.9258 - val_loss: 0.2447 - val_f1: 0.8951\n","Epoch 39/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1892 - f1: 0.9273 - val_loss: 0.2446 - val_f1: 0.8951\n","Epoch 40/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1886 - f1: 0.9263 - val_loss: 0.2445 - val_f1: 0.8931\n","Epoch 41/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1866 - f1: 0.9275 - val_loss: 0.2444 - val_f1: 0.8951\n","Epoch 42/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1869 - f1: 0.9295 - val_loss: 0.2445 - val_f1: 0.8951\n","Epoch 43/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1865 - f1: 0.9273 - val_loss: 0.2444 - val_f1: 0.8961\n","Epoch 44/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1862 - f1: 0.9295 - val_loss: 0.2443 - val_f1: 0.8941\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1865 - f1: 0.9285 - val_loss: 0.2444 - val_f1: 0.8961\n","Epoch 46/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1855 - f1: 0.9290 - val_loss: 0.2442 - val_f1: 0.8941\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1860 - f1: 0.9293 - val_loss: 0.2443 - val_f1: 0.8951\n","Epoch 48/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1839 - f1: 0.9303 - val_loss: 0.2443 - val_f1: 0.8961\n","Epoch 49/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1841 - f1: 0.9293 - val_loss: 0.2444 - val_f1: 0.8941\n","Epoch 50/50\n","4001/4001 [==============================] - 12s 3ms/step - loss: 0.1835 - f1: 0.9275 - val_loss: 0.2443 - val_f1: 0.8981\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.27015285363535935\n","test f1 score is:  0.8836232158475531\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tmAovDJfGmMJ","colab_type":"code","colab":{}},"source":[" model.save_weights('/content/drive/My Drive/Sarcasm Detection/Plots/CNN_LSTM_optimized_Weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPeTrjztdNVS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}