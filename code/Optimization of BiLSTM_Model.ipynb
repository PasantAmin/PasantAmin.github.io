{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of BiLSTM_Model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"haXfHHQJIfXR","colab_type":"code","outputId":"7d01b82b-5984-49fc-8471-56712f38d146","executionInfo":{"status":"ok","timestamp":1557910366249,"user_tz":-120,"elapsed":2644,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"WoANn0IpIo-K","colab_type":"code","outputId":"87b1956c-5422-46b3-c0a2-8c0d5f1b7aea","executionInfo":{"status":"ok","timestamp":1557910369421,"user_tz":-120,"elapsed":5787,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BhJGRlbItt9","colab_type":"code","outputId":"ebf9be30-7fa4-40ef-fadf-0315e691c07c","executionInfo":{"status":"ok","timestamp":1557910369423,"user_tz":-120,"elapsed":5760,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":198}},"source":["import pandas as pd\n","Data =  pd.read_json('/content/drive/My Drive/Sarcasm Detection/Arabic News Headlines Dataset.json', orient = 'split')\n","Data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>topic</th>\n","      <th>length</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...</td>\n","      <td>Society</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...</td>\n","      <td>Sports</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...</td>\n","      <td>Misc</td>\n","      <td>17</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...</td>\n","      <td>None</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...</td>\n","      <td>Misc</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           headlines  ... is_sarcastic\n","0  طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...  ...            1\n","1  سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...  ...            0\n","2  ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...  ...            1\n","3  وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...  ...            0\n","4  ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...  ...            1\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"eZfh50WcKc8j","colab_type":"code","colab":{}},"source":["X = Data['headlines']\n","Labels = Data['is_sarcastic']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGE1RQHEK5KP","colab_type":"code","outputId":"7417b127-df52-4480-e086-2e036cb4833c","executionInfo":{"status":"ok","timestamp":1557910369430,"user_tz":-120,"elapsed":5743,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","max_sequence_length = np.max(Data['length'])\n","print(\"max length is:\", max_sequence_length)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["max length is: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pIh6s6cxJB02","colab_type":"code","outputId":"ba231f10-c3a2-408f-a2ac-26458c83daa8","executionInfo":{"status":"ok","timestamp":1557910369884,"user_tz":-120,"elapsed":6159,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import keras\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=30000)\n","tokenizer.fit_on_texts(X)\n","sequences = tokenizer.texts_to_sequences(X)\n","\n","word_index = tokenizer.word_index   # a dictionary of each word and its index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 20595 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"enlqxEX4KZY0","colab_type":"code","outputId":"e101b918-7fbc-4567-e453-33bd4d24932a","executionInfo":{"status":"ok","timestamp":1557910369887,"user_tz":-120,"elapsed":6122,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.preprocessing.sequence import pad_sequences\n","data = pad_sequences(sequences, maxlen=max_sequence_length)\n","print('Shape of data tensor:', data.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Shape of data tensor: (6669, 34)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dYo4nQrLVVj","colab_type":"code","outputId":"bb7af395-28df-4083-a272-b8a6065d6767","executionInfo":{"status":"ok","timestamp":1557910369891,"user_tz":-120,"elapsed":6080,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.utils import to_categorical\n","labels = to_categorical(np.asarray(Labels))  ## one hot of the output\n","print('Shape of label tensor:', labels.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (6669, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4r21pAbOLz0w","colab_type":"code","colab":{}},"source":["import pickle as p\n","fastText = p.load(open('/content/drive/My Drive/Sarcasm Detection/FastText_Wiki_Embeddings.p', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxwadMk9MHir","colab_type":"code","outputId":"9516224a-4f57-4c42-94b3-b4b39b6ffe90","executionInfo":{"status":"ok","timestamp":1557910372994,"user_tz":-120,"elapsed":9154,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# prepare embedding matrix  \n","num_words = len(word_index) + 1\n","# initialize the np array\n","unKnown = list()\n","embedding_matrix = np.zeros((num_words, 300))\n","l=0\n","# find the embeddings from the pre trained embedding matrix of fast text wiki\n","for word, i in word_index.items():\n","    embedding_vector = fastText.get(word)\n","    if embedding_vector is not None:\n","        l+=1\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","      unKnown.append(word)\n","print(\"the number of words found in fast text embeddings =\", l)\n","print(\"the number of words not found in fast text embeddings =\", 20595- l)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["the number of words found in fast text embeddings = 17289\n","the number of words not found in fast text embeddings = 3306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpFKygkfMdYG","colab_type":"code","colab":{}},"source":["from keras.initializers import Constant\n","from keras.layers import Input, Embedding, Conv2D, GlobalMaxPooling2D, Dense, Dropout, LSTM, Bidirectional\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahqU4hM6Mj1F","colab_type":"code","colab":{}},"source":["# shuffle the data\n","\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","## split the data into training, testing\n","\n","nb_validation_samples = int(0.25* data.shape[0])\n","\n","x_train = data[:-nb_validation_samples]\n","y_train = labels[:-nb_validation_samples]\n","x_test = data[-nb_validation_samples:]\n","y_test = labels[-nb_validation_samples:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7FbLoXSM5O7","colab_type":"code","colab":{}},"source":["#prepare Embedding layer\n","embedding_layer = Embedding(num_words,\n","                            300,\n","                            embeddings_initializer=Constant(embedding_matrix),\n","                            input_length=max_sequence_length,\n","                            trainable=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVPVJUeoNNJv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"outputId":"9ce3d547-084d-425d-b605-34eb2e59e468","executionInfo":{"status":"ok","timestamp":1557910373444,"user_tz":-120,"elapsed":9598,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["# the model\n","\n","sequence_input = Input(shape=(max_sequence_length,), dtype='int32')                            ## Input layer\n","embedded_sequences = embedding_layer(sequence_input)                                           ## Embeddings layer\n","X = Bidirectional(LSTM(200, return_sequences=False), merge_mode='concat')(embedded_sequences)  ## BiLSTM layer\n","X = Dropout(0.5)(X)                                                                            ## Dropout layer  \n","X = Dense(30, activation='relu')(X)                                                            ## Fully Connected layer\n","X = Dropout(0.5)(X)                                                                            ## Dropout layer\n","preds = Dense(2, activation='softmax')(X)                                                      ## Softmax layer\n","model = Model(sequence_input, preds)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z3S-z0_PRYYy","colab_type":"code","colab":{}},"source":["rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9\n","                                   , epsilon=None, decay=0.3)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-nhcWJTrQcd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1983},"outputId":"79f03eac-79c1-454e-b2ff-523fa398ba5b","executionInfo":{"status":"ok","timestamp":1557911095964,"user_tz":-120,"elapsed":439998,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.4650 - acc: 0.7796 - val_loss: 0.3808 - val_acc: 0.8182\n","Epoch 2/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.3831 - acc: 0.8340 - val_loss: 0.3571 - val_acc: 0.8412\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3726 - acc: 0.8428 - val_loss: 0.3446 - val_acc: 0.8432\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3568 - acc: 0.8588 - val_loss: 0.3393 - val_acc: 0.8462\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3422 - acc: 0.8620 - val_loss: 0.3316 - val_acc: 0.8482\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3373 - acc: 0.8595 - val_loss: 0.3284 - val_acc: 0.8551\n","Epoch 7/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3372 - acc: 0.8660 - val_loss: 0.3254 - val_acc: 0.8551\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3322 - acc: 0.8700 - val_loss: 0.3224 - val_acc: 0.8561\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3345 - acc: 0.8670 - val_loss: 0.3184 - val_acc: 0.8571\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3218 - acc: 0.8718 - val_loss: 0.3159 - val_acc: 0.8601\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3232 - acc: 0.8703 - val_loss: 0.3133 - val_acc: 0.8611\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3224 - acc: 0.8700 - val_loss: 0.3113 - val_acc: 0.8621\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3202 - acc: 0.8788 - val_loss: 0.3108 - val_acc: 0.8581\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3162 - acc: 0.8738 - val_loss: 0.3079 - val_acc: 0.8641\n","Epoch 15/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3174 - acc: 0.8745 - val_loss: 0.3062 - val_acc: 0.8641\n","Epoch 16/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3102 - acc: 0.8740 - val_loss: 0.3073 - val_acc: 0.8651\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3122 - acc: 0.8763 - val_loss: 0.3058 - val_acc: 0.8641\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3064 - acc: 0.8708 - val_loss: 0.3051 - val_acc: 0.8651\n","Epoch 19/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3058 - acc: 0.8793 - val_loss: 0.3032 - val_acc: 0.8661\n","Epoch 20/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3139 - acc: 0.8763 - val_loss: 0.3015 - val_acc: 0.8661\n","Epoch 21/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.3089 - acc: 0.8770 - val_loss: 0.3005 - val_acc: 0.8671\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3009 - acc: 0.8813 - val_loss: 0.2996 - val_acc: 0.8671\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2996 - acc: 0.8785 - val_loss: 0.2988 - val_acc: 0.8681\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3024 - acc: 0.8765 - val_loss: 0.2979 - val_acc: 0.8681\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3026 - acc: 0.8810 - val_loss: 0.2986 - val_acc: 0.8691\n","Epoch 26/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2993 - acc: 0.8820 - val_loss: 0.2987 - val_acc: 0.8701\n","Epoch 27/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2987 - acc: 0.8838 - val_loss: 0.2972 - val_acc: 0.8701\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3024 - acc: 0.8813 - val_loss: 0.2957 - val_acc: 0.8701\n","Epoch 29/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.3006 - acc: 0.8803 - val_loss: 0.2948 - val_acc: 0.8691\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3030 - acc: 0.8838 - val_loss: 0.2944 - val_acc: 0.8691\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2940 - acc: 0.8840 - val_loss: 0.2960 - val_acc: 0.8721\n","Epoch 32/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2976 - acc: 0.8815 - val_loss: 0.2937 - val_acc: 0.8711\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2972 - acc: 0.8790 - val_loss: 0.2931 - val_acc: 0.8711\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2911 - acc: 0.8843 - val_loss: 0.2929 - val_acc: 0.8721\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2956 - acc: 0.8828 - val_loss: 0.2921 - val_acc: 0.8721\n","Epoch 36/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2923 - acc: 0.8848 - val_loss: 0.2917 - val_acc: 0.8721\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2995 - acc: 0.8823 - val_loss: 0.2907 - val_acc: 0.8711\n","Epoch 38/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2965 - acc: 0.8825 - val_loss: 0.2901 - val_acc: 0.8711\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2919 - acc: 0.8853 - val_loss: 0.2895 - val_acc: 0.8711\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3005 - acc: 0.8828 - val_loss: 0.2895 - val_acc: 0.8741\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2926 - acc: 0.8830 - val_loss: 0.2893 - val_acc: 0.8741\n","Epoch 42/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3022 - acc: 0.8818 - val_loss: 0.2889 - val_acc: 0.8741\n","Epoch 43/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2904 - acc: 0.8853 - val_loss: 0.2884 - val_acc: 0.8741\n","Epoch 44/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2910 - acc: 0.8880 - val_loss: 0.2882 - val_acc: 0.8741\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2888 - acc: 0.8818 - val_loss: 0.2878 - val_acc: 0.8741\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2860 - acc: 0.8883 - val_loss: 0.2881 - val_acc: 0.8741\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2883 - acc: 0.8868 - val_loss: 0.2879 - val_acc: 0.8741\n","Epoch 48/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2780 - acc: 0.8905 - val_loss: 0.2878 - val_acc: 0.8761\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2901 - acc: 0.8868 - val_loss: 0.2878 - val_acc: 0.8751\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2869 - acc: 0.8853 - val_loss: 0.2869 - val_acc: 0.8761\n","1667/1667 [==============================] - 3s 2ms/step\n","test loss is: 0.2751859915791941\n","test accuracy is:  0.8842231553689263\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fyId7r2srTz5","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","\n","def recall(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","\n","      \n","def precision(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","      \n","\n","def f1(y_true, y_pred):\n","    \n","    Precision = precision(y_true, y_pred)\n","    Recall = recall(y_true, y_pred)\n","    f1 = 2*((Precision*Recall)/(Precision+Recall+K.epsilon()))\n","    \n","    return f1\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o728BRmgrYT7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"2c127e81-5a4a-4293-b48b-baa92a327d9d","executionInfo":{"status":"ok","timestamp":1557911822549,"user_tz":-120,"elapsed":726598,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2810 - precision: 0.8880 - val_loss: 0.2864 - val_precision: 0.8751\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2848 - precision: 0.8898 - val_loss: 0.2859 - val_precision: 0.8741\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2927 - precision: 0.8845 - val_loss: 0.2857 - val_precision: 0.8761\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2867 - precision: 0.8858 - val_loss: 0.2857 - val_precision: 0.8781\n","Epoch 5/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2885 - precision: 0.8898 - val_loss: 0.2852 - val_precision: 0.8771\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2866 - precision: 0.8868 - val_loss: 0.2852 - val_precision: 0.8771\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2848 - precision: 0.8903 - val_loss: 0.2850 - val_precision: 0.8771\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2897 - precision: 0.8865 - val_loss: 0.2849 - val_precision: 0.8771\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2851 - precision: 0.8895 - val_loss: 0.2841 - val_precision: 0.8781\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2865 - precision: 0.8873 - val_loss: 0.2836 - val_precision: 0.8781\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2837 - precision: 0.8898 - val_loss: 0.2834 - val_precision: 0.8781\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2808 - precision: 0.8885 - val_loss: 0.2833 - val_precision: 0.8781\n","Epoch 13/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2857 - precision: 0.8898 - val_loss: 0.2831 - val_precision: 0.8771\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2841 - precision: 0.8860 - val_loss: 0.2829 - val_precision: 0.8771\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2791 - precision: 0.8913 - val_loss: 0.2829 - val_precision: 0.8771\n","Epoch 16/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2792 - precision: 0.8903 - val_loss: 0.2828 - val_precision: 0.8771\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2800 - precision: 0.8918 - val_loss: 0.2826 - val_precision: 0.8771\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2838 - precision: 0.8880 - val_loss: 0.2823 - val_precision: 0.8771\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2787 - precision: 0.8918 - val_loss: 0.2823 - val_precision: 0.8771\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2740 - precision: 0.8923 - val_loss: 0.2822 - val_precision: 0.8771\n","Epoch 21/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2831 - precision: 0.8880 - val_loss: 0.2817 - val_precision: 0.8771\n","Epoch 22/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2760 - precision: 0.8858 - val_loss: 0.2814 - val_precision: 0.8771\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2877 - precision: 0.8880 - val_loss: 0.2810 - val_precision: 0.8771\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2883 - precision: 0.8885 - val_loss: 0.2804 - val_precision: 0.8781\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2863 - precision: 0.8873 - val_loss: 0.2802 - val_precision: 0.8781\n","Epoch 26/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2889 - precision: 0.8913 - val_loss: 0.2800 - val_precision: 0.8781\n","Epoch 27/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2898 - precision: 0.8893 - val_loss: 0.2799 - val_precision: 0.8771\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2877 - precision: 0.8903 - val_loss: 0.2799 - val_precision: 0.8771\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2823 - precision: 0.8890 - val_loss: 0.2796 - val_precision: 0.8771\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2764 - precision: 0.8883 - val_loss: 0.2797 - val_precision: 0.8771\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2762 - precision: 0.8880 - val_loss: 0.2793 - val_precision: 0.8771\n","Epoch 32/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2748 - precision: 0.8903 - val_loss: 0.2790 - val_precision: 0.8771\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2832 - precision: 0.8908 - val_loss: 0.2789 - val_precision: 0.8771\n","Epoch 34/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2829 - precision: 0.8888 - val_loss: 0.2787 - val_precision: 0.8771\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2786 - precision: 0.8920 - val_loss: 0.2786 - val_precision: 0.8781\n","Epoch 36/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2779 - precision: 0.8870 - val_loss: 0.2785 - val_precision: 0.8781\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2773 - precision: 0.8908 - val_loss: 0.2785 - val_precision: 0.8781\n","Epoch 38/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2839 - precision: 0.8910 - val_loss: 0.2780 - val_precision: 0.8781\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2805 - precision: 0.8903 - val_loss: 0.2781 - val_precision: 0.8781\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2780 - precision: 0.8873 - val_loss: 0.2781 - val_precision: 0.8781\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2757 - precision: 0.8923 - val_loss: 0.2780 - val_precision: 0.8781\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2844 - precision: 0.8920 - val_loss: 0.2778 - val_precision: 0.8781\n","Epoch 43/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2794 - precision: 0.8938 - val_loss: 0.2778 - val_precision: 0.8781\n","Epoch 44/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2743 - precision: 0.8905 - val_loss: 0.2777 - val_precision: 0.8781\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2729 - precision: 0.8903 - val_loss: 0.2776 - val_precision: 0.8781\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2770 - precision: 0.8950 - val_loss: 0.2774 - val_precision: 0.8781\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2781 - precision: 0.8905 - val_loss: 0.2774 - val_precision: 0.8781\n","Epoch 48/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2792 - precision: 0.8913 - val_loss: 0.2775 - val_precision: 0.8781\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2716 - precision: 0.8935 - val_loss: 0.2772 - val_precision: 0.8781\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2742 - precision: 0.8943 - val_loss: 0.2773 - val_precision: 0.8781\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.26811341470052685\n","test accuracy is:  0.8890221955608878\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GrpsuT6ZrbsK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"5b1a3401-4154-46b6-a5a8-55e957ff6e84","executionInfo":{"status":"ok","timestamp":1557912548140,"user_tz":-120,"elapsed":725605,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2838 - recall: 0.8903 - val_loss: 0.2770 - val_recall: 0.8781\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2727 - recall: 0.8933 - val_loss: 0.2770 - val_recall: 0.8781\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2750 - recall: 0.8903 - val_loss: 0.2766 - val_recall: 0.8781\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2746 - recall: 0.8903 - val_loss: 0.2765 - val_recall: 0.8781\n","Epoch 5/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2776 - recall: 0.8923 - val_loss: 0.2762 - val_recall: 0.8781\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2747 - recall: 0.8935 - val_loss: 0.2762 - val_recall: 0.8781\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2772 - recall: 0.8910 - val_loss: 0.2759 - val_recall: 0.8781\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2735 - recall: 0.8928 - val_loss: 0.2758 - val_recall: 0.8781\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2750 - recall: 0.8920 - val_loss: 0.2756 - val_recall: 0.8781\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2742 - recall: 0.8923 - val_loss: 0.2758 - val_recall: 0.8781\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2753 - recall: 0.8945 - val_loss: 0.2757 - val_recall: 0.8781\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2740 - recall: 0.8880 - val_loss: 0.2755 - val_recall: 0.8781\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2773 - recall: 0.8933 - val_loss: 0.2753 - val_recall: 0.8781\n","Epoch 14/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2725 - recall: 0.8928 - val_loss: 0.2750 - val_recall: 0.8781\n","Epoch 15/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2759 - recall: 0.8925 - val_loss: 0.2749 - val_recall: 0.8781\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2701 - recall: 0.8913 - val_loss: 0.2749 - val_recall: 0.8781\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2743 - recall: 0.8918 - val_loss: 0.2749 - val_recall: 0.8781\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2727 - recall: 0.8950 - val_loss: 0.2747 - val_recall: 0.8781\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2751 - recall: 0.8933 - val_loss: 0.2745 - val_recall: 0.8781\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2773 - recall: 0.8938 - val_loss: 0.2745 - val_recall: 0.8781\n","Epoch 21/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2724 - recall: 0.8920 - val_loss: 0.2746 - val_recall: 0.8781\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2758 - recall: 0.8910 - val_loss: 0.2745 - val_recall: 0.8781\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2714 - recall: 0.8935 - val_loss: 0.2743 - val_recall: 0.8781\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2767 - recall: 0.8908 - val_loss: 0.2742 - val_recall: 0.8781\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2727 - recall: 0.8930 - val_loss: 0.2742 - val_recall: 0.8781\n","Epoch 26/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2718 - recall: 0.8945 - val_loss: 0.2740 - val_recall: 0.8781\n","Epoch 27/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2741 - recall: 0.8930 - val_loss: 0.2739 - val_recall: 0.8781\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2680 - recall: 0.8970 - val_loss: 0.2738 - val_recall: 0.8781\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2725 - recall: 0.8948 - val_loss: 0.2736 - val_recall: 0.8781\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2736 - recall: 0.8938 - val_loss: 0.2736 - val_recall: 0.8781\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2756 - recall: 0.8915 - val_loss: 0.2733 - val_recall: 0.8781\n","Epoch 32/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2720 - recall: 0.8928 - val_loss: 0.2733 - val_recall: 0.8781\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2762 - recall: 0.8925 - val_loss: 0.2732 - val_recall: 0.8781\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2663 - recall: 0.8943 - val_loss: 0.2731 - val_recall: 0.8781\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2736 - recall: 0.8910 - val_loss: 0.2731 - val_recall: 0.8781\n","Epoch 36/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2686 - recall: 0.8920 - val_loss: 0.2731 - val_recall: 0.8781\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2710 - recall: 0.8958 - val_loss: 0.2729 - val_recall: 0.8781\n","Epoch 38/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2745 - recall: 0.8968 - val_loss: 0.2729 - val_recall: 0.8781\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2694 - recall: 0.8943 - val_loss: 0.2727 - val_recall: 0.8781\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2657 - recall: 0.8985 - val_loss: 0.2727 - val_recall: 0.8781\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2697 - recall: 0.8943 - val_loss: 0.2727 - val_recall: 0.8771\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2637 - recall: 0.8958 - val_loss: 0.2727 - val_recall: 0.8771\n","Epoch 43/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2699 - recall: 0.8975 - val_loss: 0.2726 - val_recall: 0.8771\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2698 - recall: 0.8930 - val_loss: 0.2725 - val_recall: 0.8771\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2699 - recall: 0.8960 - val_loss: 0.2724 - val_recall: 0.8771\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2735 - recall: 0.8975 - val_loss: 0.2723 - val_recall: 0.8771\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2686 - recall: 0.8955 - val_loss: 0.2724 - val_recall: 0.8771\n","Epoch 48/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2666 - recall: 0.8963 - val_loss: 0.2724 - val_recall: 0.8771\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2679 - recall: 0.8928 - val_loss: 0.2725 - val_recall: 0.8771\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2662 - recall: 0.8965 - val_loss: 0.2723 - val_recall: 0.8771\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2648130561139638\n","test accuracy is:  0.8920215956808638\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"olfLuDlnrg3z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"e2eee1e0-2337-4547-d1c0-7ac9f4dee0b2","executionInfo":{"status":"ok","timestamp":1557916180999,"user_tz":-120,"elapsed":58961,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = rmsprop, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2807 - f1: 0.8928 - val_loss: 0.2720 - val_f1: 0.8771\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2690 - f1: 0.8973 - val_loss: 0.2719 - val_f1: 0.8781\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2669 - f1: 0.8958 - val_loss: 0.2719 - val_f1: 0.8781\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2713 - f1: 0.8978 - val_loss: 0.2717 - val_f1: 0.8781\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2722 - f1: 0.8953 - val_loss: 0.2715 - val_f1: 0.8781\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2722 - f1: 0.8943 - val_loss: 0.2713 - val_f1: 0.8771\n","Epoch 7/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2715 - f1: 0.8948 - val_loss: 0.2714 - val_f1: 0.8771\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2689 - f1: 0.8958 - val_loss: 0.2714 - val_f1: 0.8781\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2700 - f1: 0.8898 - val_loss: 0.2713 - val_f1: 0.8781\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2759 - f1: 0.8940 - val_loss: 0.2711 - val_f1: 0.8771\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2730 - f1: 0.8938 - val_loss: 0.2710 - val_f1: 0.8791\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2699 - f1: 0.8923 - val_loss: 0.2711 - val_f1: 0.8771\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2666 - f1: 0.8923 - val_loss: 0.2710 - val_f1: 0.8771\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2632 - f1: 0.8960 - val_loss: 0.2711 - val_f1: 0.8781\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2691 - f1: 0.8988 - val_loss: 0.2709 - val_f1: 0.8771\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2703 - f1: 0.8965 - val_loss: 0.2707 - val_f1: 0.8791\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2714 - f1: 0.8940 - val_loss: 0.2706 - val_f1: 0.8791\n","Epoch 18/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2693 - f1: 0.8950 - val_loss: 0.2706 - val_f1: 0.8791\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2710 - f1: 0.8915 - val_loss: 0.2705 - val_f1: 0.8791\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2668 - f1: 0.8985 - val_loss: 0.2704 - val_f1: 0.8791\n","Epoch 21/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2645 - f1: 0.8935 - val_loss: 0.2704 - val_f1: 0.8791\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2651 - f1: 0.8973 - val_loss: 0.2703 - val_f1: 0.8791\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2647 - f1: 0.8998 - val_loss: 0.2703 - val_f1: 0.8791\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2694 - f1: 0.8905 - val_loss: 0.2702 - val_f1: 0.8791\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2688 - f1: 0.9000 - val_loss: 0.2701 - val_f1: 0.8791\n","Epoch 26/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2633 - f1: 0.8968 - val_loss: 0.2700 - val_f1: 0.8791\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2624 - f1: 0.8938 - val_loss: 0.2700 - val_f1: 0.8791\n","Epoch 28/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2631 - f1: 0.8960 - val_loss: 0.2700 - val_f1: 0.8791\n","Epoch 29/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2699 - f1: 0.8998 - val_loss: 0.2699 - val_f1: 0.8791\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2707 - f1: 0.8965 - val_loss: 0.2698 - val_f1: 0.8801\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2627 - f1: 0.8993 - val_loss: 0.2698 - val_f1: 0.8801\n","Epoch 32/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2680 - f1: 0.8958 - val_loss: 0.2696 - val_f1: 0.8801\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2659 - f1: 0.8988 - val_loss: 0.2697 - val_f1: 0.8801\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2684 - f1: 0.8988 - val_loss: 0.2697 - val_f1: 0.8791\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2680 - f1: 0.8945 - val_loss: 0.2697 - val_f1: 0.8791\n","Epoch 36/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2687 - f1: 0.8933 - val_loss: 0.2696 - val_f1: 0.8801\n","Epoch 37/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2621 - f1: 0.8998 - val_loss: 0.2696 - val_f1: 0.8801\n","Epoch 38/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2722 - f1: 0.8920 - val_loss: 0.2695 - val_f1: 0.8791\n","Epoch 39/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2672 - f1: 0.8958 - val_loss: 0.2696 - val_f1: 0.8791\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2621 - f1: 0.8970 - val_loss: 0.2697 - val_f1: 0.8791\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2621 - f1: 0.8960 - val_loss: 0.2696 - val_f1: 0.8791\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2670 - f1: 0.8983 - val_loss: 0.2697 - val_f1: 0.8791\n","Epoch 43/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2701 - f1: 0.8973 - val_loss: 0.2694 - val_f1: 0.8791\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2686 - f1: 0.8960 - val_loss: 0.2694 - val_f1: 0.8791\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2635 - f1: 0.8958 - val_loss: 0.2693 - val_f1: 0.8791\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2670 - f1: 0.8998 - val_loss: 0.2692 - val_f1: 0.8791\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2669 - f1: 0.8990 - val_loss: 0.2691 - val_f1: 0.8801\n","Epoch 48/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2628 - f1: 0.8955 - val_loss: 0.2690 - val_f1: 0.8801\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2608 - f1: 0.8980 - val_loss: 0.2691 - val_f1: 0.8801\n","Epoch 50/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2620 - f1: 0.8973 - val_loss: 0.2689 - val_f1: 0.8801\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.26268169134587105\n","test f1 score is:  0.8926214162074811\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zPfoTnQsrmOJ","colab_type":"code","colab":{}},"source":["adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.25, amsgrad=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRx32E0_rrCx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"f0c8d169-8ab9-4a47-dcd3-d9b25faef4ca","executionInfo":{"status":"ok","timestamp":1557916181023,"user_tz":-120,"elapsed":5996,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2984 - acc: 0.8810 - val_loss: 0.2722 - val_acc: 0.8781\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2524 - acc: 0.8993 - val_loss: 0.2663 - val_acc: 0.8791\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2409 - acc: 0.9038 - val_loss: 0.2570 - val_acc: 0.8811\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2345 - acc: 0.9073 - val_loss: 0.2520 - val_acc: 0.8881\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2324 - acc: 0.9083 - val_loss: 0.2504 - val_acc: 0.8861\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2309 - acc: 0.9108 - val_loss: 0.2498 - val_acc: 0.8891\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2344 - acc: 0.9098 - val_loss: 0.2498 - val_acc: 0.8871\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2273 - acc: 0.9138 - val_loss: 0.2492 - val_acc: 0.8861\n","Epoch 9/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2249 - acc: 0.9128 - val_loss: 0.2463 - val_acc: 0.8901\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2264 - acc: 0.9118 - val_loss: 0.2449 - val_acc: 0.8901\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2283 - acc: 0.9128 - val_loss: 0.2452 - val_acc: 0.8921\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2216 - acc: 0.9128 - val_loss: 0.2451 - val_acc: 0.8931\n","Epoch 13/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2240 - acc: 0.9130 - val_loss: 0.2449 - val_acc: 0.8921\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2222 - acc: 0.9158 - val_loss: 0.2446 - val_acc: 0.8921\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2249 - acc: 0.9130 - val_loss: 0.2445 - val_acc: 0.8911\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2247 - acc: 0.9133 - val_loss: 0.2441 - val_acc: 0.8931\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2220 - acc: 0.9120 - val_loss: 0.2428 - val_acc: 0.8911\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2274 - acc: 0.9118 - val_loss: 0.2432 - val_acc: 0.8921\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2267 - acc: 0.9150 - val_loss: 0.2434 - val_acc: 0.8911\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2159 - acc: 0.9210 - val_loss: 0.2425 - val_acc: 0.8921\n","Epoch 21/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2198 - acc: 0.9150 - val_loss: 0.2411 - val_acc: 0.8921\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2178 - acc: 0.9175 - val_loss: 0.2416 - val_acc: 0.8931\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2175 - acc: 0.9163 - val_loss: 0.2418 - val_acc: 0.8931\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2156 - acc: 0.9193 - val_loss: 0.2425 - val_acc: 0.8931\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2172 - acc: 0.9168 - val_loss: 0.2416 - val_acc: 0.8931\n","Epoch 26/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2168 - acc: 0.9165 - val_loss: 0.2418 - val_acc: 0.8931\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2152 - acc: 0.9195 - val_loss: 0.2422 - val_acc: 0.8921\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2135 - acc: 0.9155 - val_loss: 0.2425 - val_acc: 0.8911\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2155 - acc: 0.9188 - val_loss: 0.2419 - val_acc: 0.8931\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2193 - acc: 0.9158 - val_loss: 0.2427 - val_acc: 0.8921\n","Epoch 31/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2196 - acc: 0.9178 - val_loss: 0.2416 - val_acc: 0.8931\n","Epoch 32/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2102 - acc: 0.9195 - val_loss: 0.2422 - val_acc: 0.8931\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2150 - acc: 0.9183 - val_loss: 0.2420 - val_acc: 0.8931\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2103 - acc: 0.9150 - val_loss: 0.2409 - val_acc: 0.8921\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2180 - acc: 0.9163 - val_loss: 0.2414 - val_acc: 0.8911\n","Epoch 36/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2131 - acc: 0.9185 - val_loss: 0.2410 - val_acc: 0.8931\n","Epoch 37/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2143 - acc: 0.9210 - val_loss: 0.2411 - val_acc: 0.8921\n","Epoch 38/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2164 - acc: 0.9175 - val_loss: 0.2395 - val_acc: 0.8921\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2139 - acc: 0.9155 - val_loss: 0.2401 - val_acc: 0.8941\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2142 - acc: 0.9163 - val_loss: 0.2404 - val_acc: 0.8921\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2109 - acc: 0.9175 - val_loss: 0.2405 - val_acc: 0.8911\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2139 - acc: 0.9193 - val_loss: 0.2401 - val_acc: 0.8931\n","Epoch 43/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2122 - acc: 0.9195 - val_loss: 0.2399 - val_acc: 0.8951\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2121 - acc: 0.9200 - val_loss: 0.2400 - val_acc: 0.8931\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2204 - acc: 0.9188 - val_loss: 0.2402 - val_acc: 0.8911\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2161 - acc: 0.9218 - val_loss: 0.2402 - val_acc: 0.8911\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2089 - acc: 0.9195 - val_loss: 0.2400 - val_acc: 0.8921\n","Epoch 48/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2113 - acc: 0.9168 - val_loss: 0.2397 - val_acc: 0.8931\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2116 - acc: 0.9195 - val_loss: 0.2397 - val_acc: 0.8931\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2085 - acc: 0.9183 - val_loss: 0.2396 - val_acc: 0.8931\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2413306945837681\n","test accuracy is:  0.9022195561245379\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1zEIgZnvrrq2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"9f4bfc82-a15b-4e39-b801-5888bc387502","executionInfo":{"status":"ok","timestamp":1557916181027,"user_tz":-120,"elapsed":4433,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2150 - precision: 0.9195 - val_loss: 0.2401 - val_precision: 0.8931\n","Epoch 2/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2090 - precision: 0.9190 - val_loss: 0.2391 - val_precision: 0.8931\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2115 - precision: 0.9208 - val_loss: 0.2390 - val_precision: 0.8931\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2079 - precision: 0.9170 - val_loss: 0.2392 - val_precision: 0.8921\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2117 - precision: 0.9223 - val_loss: 0.2392 - val_precision: 0.8941\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2147 - precision: 0.9205 - val_loss: 0.2390 - val_precision: 0.8931\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2085 - precision: 0.9178 - val_loss: 0.2394 - val_precision: 0.8931\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2095 - precision: 0.9208 - val_loss: 0.2392 - val_precision: 0.8931\n","Epoch 9/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2093 - precision: 0.9190 - val_loss: 0.2395 - val_precision: 0.8931\n","Epoch 10/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2126 - precision: 0.9188 - val_loss: 0.2390 - val_precision: 0.8931\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2102 - precision: 0.9170 - val_loss: 0.2390 - val_precision: 0.8931\n","Epoch 12/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2179 - precision: 0.9198 - val_loss: 0.2387 - val_precision: 0.8931\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2139 - precision: 0.9215 - val_loss: 0.2386 - val_precision: 0.8941\n","Epoch 14/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2071 - precision: 0.9243 - val_loss: 0.2390 - val_precision: 0.8951\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2073 - precision: 0.9220 - val_loss: 0.2382 - val_precision: 0.8921\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2113 - precision: 0.9205 - val_loss: 0.2379 - val_precision: 0.8931\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2037 - precision: 0.9213 - val_loss: 0.2380 - val_precision: 0.8941\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2062 - precision: 0.9198 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2114 - precision: 0.9210 - val_loss: 0.2380 - val_precision: 0.8941\n","Epoch 20/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2088 - precision: 0.9240 - val_loss: 0.2386 - val_precision: 0.8941\n","Epoch 21/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2024 - precision: 0.9215 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2110 - precision: 0.9195 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2062 - precision: 0.9188 - val_loss: 0.2385 - val_precision: 0.8941\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2121 - precision: 0.9170 - val_loss: 0.2380 - val_precision: 0.8941\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2037 - precision: 0.9213 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 26/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2078 - precision: 0.9210 - val_loss: 0.2385 - val_precision: 0.8951\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2081 - precision: 0.9205 - val_loss: 0.2386 - val_precision: 0.8951\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2035 - precision: 0.9238 - val_loss: 0.2385 - val_precision: 0.8941\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2070 - precision: 0.9205 - val_loss: 0.2386 - val_precision: 0.8951\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2035 - precision: 0.9188 - val_loss: 0.2386 - val_precision: 0.8951\n","Epoch 31/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2090 - precision: 0.9188 - val_loss: 0.2386 - val_precision: 0.8951\n","Epoch 32/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2071 - precision: 0.9210 - val_loss: 0.2384 - val_precision: 0.8941\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2100 - precision: 0.9210 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2020 - precision: 0.9218 - val_loss: 0.2382 - val_precision: 0.8941\n","Epoch 35/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2024 - precision: 0.9215 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 36/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2088 - precision: 0.9208 - val_loss: 0.2382 - val_precision: 0.8941\n","Epoch 37/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2043 - precision: 0.9210 - val_loss: 0.2381 - val_precision: 0.8941\n","Epoch 38/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2018 - precision: 0.9218 - val_loss: 0.2381 - val_precision: 0.8941\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2082 - precision: 0.9220 - val_loss: 0.2383 - val_precision: 0.8941\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2058 - precision: 0.9193 - val_loss: 0.2384 - val_precision: 0.8951\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2035 - precision: 0.9220 - val_loss: 0.2386 - val_precision: 0.8951\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2034 - precision: 0.9220 - val_loss: 0.2383 - val_precision: 0.8951\n","Epoch 43/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2058 - precision: 0.9233 - val_loss: 0.2375 - val_precision: 0.8941\n","Epoch 44/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2089 - precision: 0.9213 - val_loss: 0.2377 - val_precision: 0.8951\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2103 - precision: 0.9205 - val_loss: 0.2377 - val_precision: 0.8951\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2053 - precision: 0.9225 - val_loss: 0.2378 - val_precision: 0.8941\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2070 - precision: 0.9243 - val_loss: 0.2378 - val_precision: 0.8941\n","Epoch 48/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2053 - precision: 0.9220 - val_loss: 0.2377 - val_precision: 0.8941\n","Epoch 49/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2083 - precision: 0.9235 - val_loss: 0.2372 - val_precision: 0.8941\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2059 - precision: 0.9218 - val_loss: 0.2372 - val_precision: 0.8941\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2402759645967764\n","test accuracy is:  0.9028194361485331\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"84hRzlAirsQA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"2357297f-7798-4008-a519-ace9a6c4f500","executionInfo":{"status":"ok","timestamp":1557916181030,"user_tz":-120,"elapsed":2609,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2072 - recall: 0.9213 - val_loss: 0.2373 - val_recall: 0.8951\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2057 - recall: 0.9213 - val_loss: 0.2372 - val_recall: 0.8941\n","Epoch 3/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2031 - recall: 0.9255 - val_loss: 0.2379 - val_recall: 0.8951\n","Epoch 4/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2091 - recall: 0.9213 - val_loss: 0.2374 - val_recall: 0.8951\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2020 - recall: 0.9253 - val_loss: 0.2374 - val_recall: 0.8951\n","Epoch 6/50\n","4001/4001 [==============================] - 18s 4ms/step - loss: 0.2014 - recall: 0.9210 - val_loss: 0.2377 - val_recall: 0.8951\n","Epoch 7/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2026 - recall: 0.9223 - val_loss: 0.2377 - val_recall: 0.8951\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2021 - recall: 0.9240 - val_loss: 0.2378 - val_recall: 0.8951\n","Epoch 9/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2023 - recall: 0.9230 - val_loss: 0.2377 - val_recall: 0.8951\n","Epoch 10/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2000 - recall: 0.9228 - val_loss: 0.2377 - val_recall: 0.8951\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2049 - recall: 0.9213 - val_loss: 0.2372 - val_recall: 0.8941\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2046 - recall: 0.9238 - val_loss: 0.2368 - val_recall: 0.8951\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2069 - recall: 0.9213 - val_loss: 0.2368 - val_recall: 0.8951\n","Epoch 14/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2030 - recall: 0.9225 - val_loss: 0.2371 - val_recall: 0.8951\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1993 - recall: 0.9248 - val_loss: 0.2370 - val_recall: 0.8941\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2039 - recall: 0.9238 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 17/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2009 - recall: 0.9238 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2019 - recall: 0.9240 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2048 - recall: 0.9218 - val_loss: 0.2372 - val_recall: 0.8951\n","Epoch 20/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2027 - recall: 0.9240 - val_loss: 0.2374 - val_recall: 0.8951\n","Epoch 21/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1967 - recall: 0.9245 - val_loss: 0.2375 - val_recall: 0.8961\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2031 - recall: 0.9223 - val_loss: 0.2375 - val_recall: 0.8951\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2051 - recall: 0.9243 - val_loss: 0.2373 - val_recall: 0.8951\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1993 - recall: 0.9253 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 25/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2041 - recall: 0.9228 - val_loss: 0.2369 - val_recall: 0.8951\n","Epoch 26/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2010 - recall: 0.9265 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2015 - recall: 0.9245 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 28/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2005 - recall: 0.9243 - val_loss: 0.2368 - val_recall: 0.8951\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1958 - recall: 0.9243 - val_loss: 0.2367 - val_recall: 0.8941\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2064 - recall: 0.9235 - val_loss: 0.2369 - val_recall: 0.8951\n","Epoch 31/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1998 - recall: 0.9250 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 32/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2010 - recall: 0.9220 - val_loss: 0.2369 - val_recall: 0.8951\n","Epoch 33/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2036 - recall: 0.9230 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1992 - recall: 0.9233 - val_loss: 0.2370 - val_recall: 0.8951\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2002 - recall: 0.9235 - val_loss: 0.2372 - val_recall: 0.8951\n","Epoch 36/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2066 - recall: 0.9220 - val_loss: 0.2369 - val_recall: 0.8951\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2028 - recall: 0.9255 - val_loss: 0.2371 - val_recall: 0.8961\n","Epoch 38/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2002 - recall: 0.9248 - val_loss: 0.2371 - val_recall: 0.8961\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1981 - recall: 0.9255 - val_loss: 0.2372 - val_recall: 0.8961\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2006 - recall: 0.9235 - val_loss: 0.2372 - val_recall: 0.8961\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1970 - recall: 0.9253 - val_loss: 0.2372 - val_recall: 0.8961\n","Epoch 42/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2006 - recall: 0.9243 - val_loss: 0.2373 - val_recall: 0.8961\n","Epoch 43/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2006 - recall: 0.9228 - val_loss: 0.2370 - val_recall: 0.8961\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2027 - recall: 0.9248 - val_loss: 0.2369 - val_recall: 0.8951\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2000 - recall: 0.9280 - val_loss: 0.2366 - val_recall: 0.8941\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2029 - recall: 0.9213 - val_loss: 0.2367 - val_recall: 0.8951\n","Epoch 47/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2005 - recall: 0.9233 - val_loss: 0.2368 - val_recall: 0.8951\n","Epoch 48/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1971 - recall: 0.9240 - val_loss: 0.2370 - val_recall: 0.8961\n","Epoch 49/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.1995 - recall: 0.9248 - val_loss: 0.2371 - val_recall: 0.8961\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2019 - recall: 0.9228 - val_loss: 0.2371 - val_recall: 0.8961\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.24107438367000938\n","test accuracy is:  0.9040191961965235\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lgxw5aj8rswW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"e4cfd0ac-2f67-4f7a-938a-7fc01d003439","executionInfo":{"status":"ok","timestamp":1557916205028,"user_tz":-120,"elapsed":24907,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = adam, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2001 - f1: 0.9243 - val_loss: 0.2377 - val_f1: 0.8971\n","Epoch 2/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2001 - f1: 0.9225 - val_loss: 0.2375 - val_f1: 0.8981\n","Epoch 3/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2028 - f1: 0.9240 - val_loss: 0.2375 - val_f1: 0.8971\n","Epoch 4/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1980 - f1: 0.9238 - val_loss: 0.2375 - val_f1: 0.8981\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1982 - f1: 0.9225 - val_loss: 0.2373 - val_f1: 0.8981\n","Epoch 6/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1993 - f1: 0.9250 - val_loss: 0.2373 - val_f1: 0.8981\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1953 - f1: 0.9268 - val_loss: 0.2374 - val_f1: 0.8981\n","Epoch 8/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2020 - f1: 0.9250 - val_loss: 0.2370 - val_f1: 0.8981\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2028 - f1: 0.9230 - val_loss: 0.2371 - val_f1: 0.8981\n","Epoch 10/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2009 - f1: 0.9223 - val_loss: 0.2371 - val_f1: 0.8981\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2014 - f1: 0.9223 - val_loss: 0.2372 - val_f1: 0.8981\n","Epoch 12/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1965 - f1: 0.9255 - val_loss: 0.2372 - val_f1: 0.8981\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1999 - f1: 0.9253 - val_loss: 0.2370 - val_f1: 0.8971\n","Epoch 14/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2081 - f1: 0.9233 - val_loss: 0.2369 - val_f1: 0.8971\n","Epoch 15/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2015 - f1: 0.9250 - val_loss: 0.2369 - val_f1: 0.8971\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1981 - f1: 0.9258 - val_loss: 0.2368 - val_f1: 0.8961\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2023 - f1: 0.9228 - val_loss: 0.2368 - val_f1: 0.8971\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1999 - f1: 0.9238 - val_loss: 0.2368 - val_f1: 0.8961\n","Epoch 19/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1995 - f1: 0.9235 - val_loss: 0.2368 - val_f1: 0.8971\n","Epoch 20/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.1976 - f1: 0.9268 - val_loss: 0.2370 - val_f1: 0.8981\n","Epoch 21/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1997 - f1: 0.9225 - val_loss: 0.2371 - val_f1: 0.8981\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1981 - f1: 0.9258 - val_loss: 0.2371 - val_f1: 0.8981\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1991 - f1: 0.9245 - val_loss: 0.2370 - val_f1: 0.8981\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2019 - f1: 0.9233 - val_loss: 0.2367 - val_f1: 0.8961\n","Epoch 25/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1976 - f1: 0.9263 - val_loss: 0.2366 - val_f1: 0.8961\n","Epoch 26/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1985 - f1: 0.9245 - val_loss: 0.2369 - val_f1: 0.8981\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1983 - f1: 0.9255 - val_loss: 0.2370 - val_f1: 0.8981\n","Epoch 28/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1993 - f1: 0.9260 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2004 - f1: 0.9235 - val_loss: 0.2365 - val_f1: 0.8961\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1978 - f1: 0.9253 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 31/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2007 - f1: 0.9238 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 32/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1933 - f1: 0.9235 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2022 - f1: 0.9245 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1986 - f1: 0.9258 - val_loss: 0.2365 - val_f1: 0.8961\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1962 - f1: 0.9268 - val_loss: 0.2364 - val_f1: 0.8961\n","Epoch 36/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2024 - f1: 0.9258 - val_loss: 0.2365 - val_f1: 0.8971\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1976 - f1: 0.9250 - val_loss: 0.2366 - val_f1: 0.8981\n","Epoch 38/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2015 - f1: 0.9260 - val_loss: 0.2365 - val_f1: 0.8971\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2002 - f1: 0.9275 - val_loss: 0.2365 - val_f1: 0.8971\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1984 - f1: 0.9240 - val_loss: 0.2365 - val_f1: 0.8981\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1993 - f1: 0.9223 - val_loss: 0.2366 - val_f1: 0.8981\n","Epoch 42/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.1973 - f1: 0.9268 - val_loss: 0.2366 - val_f1: 0.8981\n","Epoch 43/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2043 - f1: 0.9213 - val_loss: 0.2366 - val_f1: 0.8981\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1991 - f1: 0.9268 - val_loss: 0.2366 - val_f1: 0.8981\n","Epoch 45/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2018 - f1: 0.9240 - val_loss: 0.2365 - val_f1: 0.8981\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1978 - f1: 0.9268 - val_loss: 0.2364 - val_f1: 0.8971\n","Epoch 47/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2024 - f1: 0.9258 - val_loss: 0.2363 - val_f1: 0.8971\n","Epoch 48/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1985 - f1: 0.9268 - val_loss: 0.2363 - val_f1: 0.8971\n","Epoch 49/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1980 - f1: 0.9270 - val_loss: 0.2364 - val_f1: 0.8981\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1955 - f1: 0.9245 - val_loss: 0.2365 - val_f1: 0.8981\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2408823439226797\n","test f1 score is:  0.9046190189042346\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ULXSGiPertU4","colab_type":"code","colab":{}},"source":["model.save_weights('/content/drive/My Drive/Sarcasm Detection/Plots/BiLSTM_optimized_Weights.h5')"],"execution_count":0,"outputs":[]}]}