{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of LSTM_Model.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"haXfHHQJIfXR","colab_type":"code","outputId":"8cb7909d-b544-4b5f-d1b8-cb6da2c55cc9","executionInfo":{"status":"ok","timestamp":1557898514145,"user_tz":-120,"elapsed":2564,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"WoANn0IpIo-K","colab_type":"code","outputId":"261ffc8f-57b5-49bc-9ece-f2fbe2fba43e","executionInfo":{"status":"ok","timestamp":1557898539469,"user_tz":-120,"elapsed":4152,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BhJGRlbItt9","colab_type":"code","outputId":"bb021b20-69ed-4684-bc91-f944226b0ca0","executionInfo":{"status":"ok","timestamp":1557898542334,"user_tz":-120,"elapsed":2186,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":198}},"source":["import pandas as pd\n","Data =  pd.read_json('/content/drive/My Drive/Sarcasm Detection/Arabic News Headlines Dataset.json', orient = 'split')\n","Data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>topic</th>\n","      <th>length</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...</td>\n","      <td>Society</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...</td>\n","      <td>Sports</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...</td>\n","      <td>Misc</td>\n","      <td>17</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...</td>\n","      <td>None</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...</td>\n","      <td>Misc</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           headlines  ... is_sarcastic\n","0  طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...  ...            1\n","1  سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...  ...            0\n","2  ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...  ...            1\n","3  وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...  ...            0\n","4  ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...  ...            1\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"eZfh50WcKc8j","colab_type":"code","colab":{}},"source":["X = Data['headlines']\n","Labels = Data['is_sarcastic']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGE1RQHEK5KP","colab_type":"code","outputId":"b73e3e4d-6d69-4426-cfa5-ef529c02816d","executionInfo":{"status":"ok","timestamp":1557898554231,"user_tz":-120,"elapsed":9066,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","max_sequence_length = np.max(Data['length'])\n","print(\"max length is:\", max_sequence_length)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["max length is: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pIh6s6cxJB02","colab_type":"code","outputId":"84f19535-5b74-47ce-82a7-ec70eb24e528","executionInfo":{"status":"ok","timestamp":1557898564686,"user_tz":-120,"elapsed":2083,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import keras\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=30000)\n","tokenizer.fit_on_texts(X)\n","sequences = tokenizer.texts_to_sequences(X)\n","\n","word_index = tokenizer.word_index   # a dictionary of each word and its index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 20595 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"enlqxEX4KZY0","colab_type":"code","outputId":"9bb05eea-bdde-441f-844e-2c6a98a0b08d","executionInfo":{"status":"ok","timestamp":1557898566946,"user_tz":-120,"elapsed":1845,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.preprocessing.sequence import pad_sequences\n","data = pad_sequences(sequences, maxlen=max_sequence_length)\n","print('Shape of data tensor:', data.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Shape of data tensor: (6669, 34)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dYo4nQrLVVj","colab_type":"code","outputId":"121d904a-201c-4fd2-dce3-94d76bbaed4c","executionInfo":{"status":"ok","timestamp":1557898569170,"user_tz":-120,"elapsed":1335,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.utils import to_categorical\n","labels = to_categorical(np.asarray(Labels))  ## one hot of the output\n","print('Shape of label tensor:', labels.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (6669, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4r21pAbOLz0w","colab_type":"code","colab":{}},"source":["import pickle as p\n","fastText = p.load(open('/content/drive/My Drive/Sarcasm Detection/FastText_Wiki_Embeddings.p', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxwadMk9MHir","colab_type":"code","outputId":"648a9eb5-c943-491c-bf5e-69ca8dd5bf85","executionInfo":{"status":"ok","timestamp":1557898600305,"user_tz":-120,"elapsed":2567,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# prepare embedding matrix  (matrix of embeddings of the words in our dataset)\n","num_words = len(word_index) + 1\n","# initialize the np array\n","unKnown = list()\n","embedding_matrix = np.zeros((num_words, 300))\n","l=0\n","# find the embeddings from the pre trained embedding matrix of fast text wiki\n","for word, i in word_index.items():\n","    embedding_vector = fastText.get(word)\n","    if embedding_vector is not None:\n","        l+=1\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","      unKnown.append(word)\n","print(\"the number of words found in fast text embeddings =\", l)\n","print(\"the number of words not found in fast text embeddings =\", 20595- l)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["the number of words found in fast text embeddings = 17289\n","the number of words not found in fast text embeddings = 3306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpFKygkfMdYG","colab_type":"code","colab":{}},"source":["from keras.initializers import Constant\n","from keras.layers import Input, Embedding, Conv2D, GlobalMaxPooling2D, Dense, Dropout, LSTM, Bidirectional\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahqU4hM6Mj1F","colab_type":"code","colab":{}},"source":["# shuffle the data\n","\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","## split the data into training, testing\n","\n","nb_validation_samples = int(0.25* data.shape[0])\n","\n","x_train = data[:-nb_validation_samples]\n","y_train = labels[:-nb_validation_samples]\n","x_test = data[-nb_validation_samples:]\n","y_test = labels[-nb_validation_samples:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7FbLoXSM5O7","colab_type":"code","colab":{}},"source":["embedding_layer = Embedding(num_words,\n","                            300,\n","                            embeddings_initializer=Constant(embedding_matrix),\n","                            input_length=max_sequence_length,\n","                            trainable=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVPVJUeoNNJv","colab_type":"code","colab":{}},"source":["# the model\n","\n","sequence_input = Input(shape=(max_sequence_length,), dtype='int32')             ## input layer\n","embedded_sequences = embedding_layer(sequence_input)                            ## embeddings layer\n","X = LSTM(128, return_sequences=True)(embedded_sequences)\n","X = Dropout(0.5)(X)\n","X = LSTM(128, return_sequences=False)(X)\n","X = Dropout(0.5)(X)\n","X = Dense(30, activation='relu')(X)                                      \n","X = Dropout(0.5)(X)                            \n","preds = Dense(2, activation='softmax')(X)                                       ## softmax layer\n","\n","model = Model(sequence_input, preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnDBiJYXBUjV","colab_type":"code","colab":{}},"source":["rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9\n","                                   , epsilon=None, decay=0.3)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KW0P0DASrKv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"875ac045-fcca-4dd4-875c-c932d5431100","executionInfo":{"status":"ok","timestamp":1557904316973,"user_tz":-120,"elapsed":4417,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.6145 - acc: 0.6886 - val_loss: 0.5345 - val_acc: 0.8232\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.5205 - acc: 0.7903 - val_loss: 0.4683 - val_acc: 0.8392\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4864 - acc: 0.8015 - val_loss: 0.4324 - val_acc: 0.8472\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4597 - acc: 0.8138 - val_loss: 0.4112 - val_acc: 0.8551\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4460 - acc: 0.8143 - val_loss: 0.3972 - val_acc: 0.8571\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4356 - acc: 0.8185 - val_loss: 0.3868 - val_acc: 0.8591\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4259 - acc: 0.8253 - val_loss: 0.3790 - val_acc: 0.8611\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.4186 - acc: 0.8203 - val_loss: 0.3730 - val_acc: 0.8631\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4126 - acc: 0.8340 - val_loss: 0.3679 - val_acc: 0.8651\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4013 - acc: 0.8293 - val_loss: 0.3636 - val_acc: 0.8631\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4095 - acc: 0.8313 - val_loss: 0.3602 - val_acc: 0.8641\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3990 - acc: 0.8358 - val_loss: 0.3571 - val_acc: 0.8611\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3941 - acc: 0.8388 - val_loss: 0.3542 - val_acc: 0.8611\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.4008 - acc: 0.8355 - val_loss: 0.3521 - val_acc: 0.8621\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3989 - acc: 0.8315 - val_loss: 0.3498 - val_acc: 0.8611\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3934 - acc: 0.8350 - val_loss: 0.3480 - val_acc: 0.8601\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3844 - acc: 0.8403 - val_loss: 0.3464 - val_acc: 0.8621\n","Epoch 18/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3915 - acc: 0.8405 - val_loss: 0.3450 - val_acc: 0.8611\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3904 - acc: 0.8358 - val_loss: 0.3437 - val_acc: 0.8611\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3861 - acc: 0.8348 - val_loss: 0.3427 - val_acc: 0.8641\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3892 - acc: 0.8385 - val_loss: 0.3414 - val_acc: 0.8631\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3830 - acc: 0.8410 - val_loss: 0.3401 - val_acc: 0.8621\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3824 - acc: 0.8348 - val_loss: 0.3391 - val_acc: 0.8641\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3801 - acc: 0.8415 - val_loss: 0.3380 - val_acc: 0.8631\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3795 - acc: 0.8398 - val_loss: 0.3371 - val_acc: 0.8641\n","Epoch 26/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3808 - acc: 0.8375 - val_loss: 0.3364 - val_acc: 0.8661\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3742 - acc: 0.8430 - val_loss: 0.3355 - val_acc: 0.8661\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3802 - acc: 0.8390 - val_loss: 0.3347 - val_acc: 0.8671\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3820 - acc: 0.8440 - val_loss: 0.3342 - val_acc: 0.8681\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3735 - acc: 0.8445 - val_loss: 0.3335 - val_acc: 0.8691\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3712 - acc: 0.8455 - val_loss: 0.3327 - val_acc: 0.8681\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3712 - acc: 0.8438 - val_loss: 0.3321 - val_acc: 0.8681\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3678 - acc: 0.8448 - val_loss: 0.3314 - val_acc: 0.8681\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3750 - acc: 0.8373 - val_loss: 0.3308 - val_acc: 0.8681\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3689 - acc: 0.8530 - val_loss: 0.3303 - val_acc: 0.8691\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3686 - acc: 0.8440 - val_loss: 0.3298 - val_acc: 0.8691\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3792 - acc: 0.8423 - val_loss: 0.3294 - val_acc: 0.8711\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3760 - acc: 0.8420 - val_loss: 0.3288 - val_acc: 0.8711\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3680 - acc: 0.8455 - val_loss: 0.3283 - val_acc: 0.8701\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3710 - acc: 0.8453 - val_loss: 0.3278 - val_acc: 0.8701\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3726 - acc: 0.8505 - val_loss: 0.3274 - val_acc: 0.8701\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3668 - acc: 0.8495 - val_loss: 0.3269 - val_acc: 0.8731\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3668 - acc: 0.8475 - val_loss: 0.3265 - val_acc: 0.8731\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3664 - acc: 0.8510 - val_loss: 0.3260 - val_acc: 0.8721\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3698 - acc: 0.8465 - val_loss: 0.3256 - val_acc: 0.8731\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3639 - acc: 0.8503 - val_loss: 0.3252 - val_acc: 0.8731\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3668 - acc: 0.8480 - val_loss: 0.3248 - val_acc: 0.8731\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3622 - acc: 0.8498 - val_loss: 0.3245 - val_acc: 0.8741\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3618 - acc: 0.8495 - val_loss: 0.3241 - val_acc: 0.8741\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3639 - acc: 0.8525 - val_loss: 0.3237 - val_acc: 0.8741\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.3396040060309929\n","test accuracy is:  0.8494301140129602\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GrZDLtjWBcz1","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","\n","def recall(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","\n","      \n","def precision(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","      \n","\n","def f1(y_true, y_pred):\n","    \n","    Precision = precision(y_true, y_pred)\n","    Recall = recall(y_true, y_pred)\n","    f1 = 2*((Precision*Recall)/(Precision+Recall+K.epsilon()))\n","    \n","    return f1\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0awKhM-UBn5r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"c7cee6d0-7c78-421b-e47f-bbab9dcaae66","executionInfo":{"status":"ok","timestamp":1557904731483,"user_tz":-120,"elapsed":414906,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.3626 - precision: 0.8493 - val_loss: 0.3234 - val_precision: 0.8741\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3613 - precision: 0.8480 - val_loss: 0.3230 - val_precision: 0.8721\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3689 - precision: 0.8470 - val_loss: 0.3227 - val_precision: 0.8741\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3595 - precision: 0.8473 - val_loss: 0.3224 - val_precision: 0.8741\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3646 - precision: 0.8520 - val_loss: 0.3221 - val_precision: 0.8751\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3592 - precision: 0.8535 - val_loss: 0.3218 - val_precision: 0.8751\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3647 - precision: 0.8493 - val_loss: 0.3216 - val_precision: 0.8751\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3609 - precision: 0.8503 - val_loss: 0.3214 - val_precision: 0.8751\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3645 - precision: 0.8515 - val_loss: 0.3211 - val_precision: 0.8751\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3609 - precision: 0.8535 - val_loss: 0.3208 - val_precision: 0.8751\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3679 - precision: 0.8508 - val_loss: 0.3205 - val_precision: 0.8751\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3636 - precision: 0.8478 - val_loss: 0.3202 - val_precision: 0.8751\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3605 - precision: 0.8483 - val_loss: 0.3199 - val_precision: 0.8751\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3658 - precision: 0.8455 - val_loss: 0.3197 - val_precision: 0.8751\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3607 - precision: 0.8525 - val_loss: 0.3195 - val_precision: 0.8751\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3622 - precision: 0.8508 - val_loss: 0.3193 - val_precision: 0.8751\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3653 - precision: 0.8480 - val_loss: 0.3191 - val_precision: 0.8761\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3590 - precision: 0.8495 - val_loss: 0.3189 - val_precision: 0.8761\n","Epoch 19/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3609 - precision: 0.8473 - val_loss: 0.3187 - val_precision: 0.8761\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3567 - precision: 0.8538 - val_loss: 0.3185 - val_precision: 0.8761\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3589 - precision: 0.8480 - val_loss: 0.3183 - val_precision: 0.8761\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3607 - precision: 0.8523 - val_loss: 0.3180 - val_precision: 0.8761\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3662 - precision: 0.8478 - val_loss: 0.3178 - val_precision: 0.8771\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3604 - precision: 0.8523 - val_loss: 0.3175 - val_precision: 0.8761\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3608 - precision: 0.8550 - val_loss: 0.3174 - val_precision: 0.8771\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3552 - precision: 0.8525 - val_loss: 0.3172 - val_precision: 0.8771\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3607 - precision: 0.8468 - val_loss: 0.3170 - val_precision: 0.8771\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3547 - precision: 0.8498 - val_loss: 0.3168 - val_precision: 0.8781\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3593 - precision: 0.8500 - val_loss: 0.3167 - val_precision: 0.8771\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3551 - precision: 0.8485 - val_loss: 0.3165 - val_precision: 0.8781\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3527 - precision: 0.8538 - val_loss: 0.3163 - val_precision: 0.8781\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3515 - precision: 0.8575 - val_loss: 0.3161 - val_precision: 0.8791\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3543 - precision: 0.8513 - val_loss: 0.3160 - val_precision: 0.8791\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3516 - precision: 0.8500 - val_loss: 0.3159 - val_precision: 0.8781\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3617 - precision: 0.8550 - val_loss: 0.3157 - val_precision: 0.8791\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3560 - precision: 0.8533 - val_loss: 0.3154 - val_precision: 0.8791\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3513 - precision: 0.8508 - val_loss: 0.3152 - val_precision: 0.8791\n","Epoch 38/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3477 - precision: 0.8568 - val_loss: 0.3151 - val_precision: 0.8791\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3505 - precision: 0.8555 - val_loss: 0.3149 - val_precision: 0.8791\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3563 - precision: 0.8485 - val_loss: 0.3147 - val_precision: 0.8791\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3541 - precision: 0.8493 - val_loss: 0.3146 - val_precision: 0.8791\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3563 - precision: 0.8558 - val_loss: 0.3145 - val_precision: 0.8791\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3638 - precision: 0.8550 - val_loss: 0.3143 - val_precision: 0.8791\n","Epoch 44/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3531 - precision: 0.8568 - val_loss: 0.3141 - val_precision: 0.8791\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3557 - precision: 0.8560 - val_loss: 0.3140 - val_precision: 0.8791\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3538 - precision: 0.8505 - val_loss: 0.3138 - val_precision: 0.8781\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3543 - precision: 0.8513 - val_loss: 0.3136 - val_precision: 0.8781\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3525 - precision: 0.8505 - val_loss: 0.3135 - val_precision: 0.8771\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3572 - precision: 0.8553 - val_loss: 0.3134 - val_precision: 0.8771\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3517 - precision: 0.8480 - val_loss: 0.3133 - val_precision: 0.8791\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.3310472126055708\n","test accuracy is:  0.8530293941569314\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VMNbkVuBBs7x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"4f6e7606-3b24-4f91-8052-ee444f8df66a","executionInfo":{"status":"ok","timestamp":1557905390071,"user_tz":-120,"elapsed":658604,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = rmsprop,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3549 - recall: 0.8535 - val_loss: 0.3131 - val_recall: 0.8781\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3510 - recall: 0.8510 - val_loss: 0.3130 - val_recall: 0.8781\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3528 - recall: 0.8563 - val_loss: 0.3128 - val_recall: 0.8771\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3502 - recall: 0.8560 - val_loss: 0.3128 - val_recall: 0.8811\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3557 - recall: 0.8525 - val_loss: 0.3127 - val_recall: 0.8811\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3516 - recall: 0.8545 - val_loss: 0.3125 - val_recall: 0.8811\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3529 - recall: 0.8535 - val_loss: 0.3124 - val_recall: 0.8801\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3503 - recall: 0.8568 - val_loss: 0.3123 - val_recall: 0.8811\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3509 - recall: 0.8590 - val_loss: 0.3121 - val_recall: 0.8811\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3416 - recall: 0.8575 - val_loss: 0.3120 - val_recall: 0.8801\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3493 - recall: 0.8545 - val_loss: 0.3119 - val_recall: 0.8811\n","Epoch 12/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3541 - recall: 0.8558 - val_loss: 0.3118 - val_recall: 0.8811\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3495 - recall: 0.8548 - val_loss: 0.3117 - val_recall: 0.8811\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3534 - recall: 0.8565 - val_loss: 0.3116 - val_recall: 0.8811\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3458 - recall: 0.8595 - val_loss: 0.3115 - val_recall: 0.8811\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3514 - recall: 0.8533 - val_loss: 0.3114 - val_recall: 0.8811\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3488 - recall: 0.8530 - val_loss: 0.3113 - val_recall: 0.8811\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3459 - recall: 0.8560 - val_loss: 0.3111 - val_recall: 0.8801\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3525 - recall: 0.8538 - val_loss: 0.3110 - val_recall: 0.8801\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3477 - recall: 0.8620 - val_loss: 0.3109 - val_recall: 0.8801\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3514 - recall: 0.8565 - val_loss: 0.3108 - val_recall: 0.8801\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3457 - recall: 0.8618 - val_loss: 0.3107 - val_recall: 0.8801\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3484 - recall: 0.8555 - val_loss: 0.3105 - val_recall: 0.8801\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3508 - recall: 0.8558 - val_loss: 0.3104 - val_recall: 0.8801\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3488 - recall: 0.8538 - val_loss: 0.3102 - val_recall: 0.8801\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3464 - recall: 0.8538 - val_loss: 0.3101 - val_recall: 0.8801\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3465 - recall: 0.8578 - val_loss: 0.3100 - val_recall: 0.8801\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3516 - recall: 0.8563 - val_loss: 0.3099 - val_recall: 0.8801\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3449 - recall: 0.8525 - val_loss: 0.3098 - val_recall: 0.8801\n","Epoch 30/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3500 - recall: 0.8568 - val_loss: 0.3097 - val_recall: 0.8801\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3469 - recall: 0.8593 - val_loss: 0.3096 - val_recall: 0.8801\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3486 - recall: 0.8608 - val_loss: 0.3095 - val_recall: 0.8801\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3457 - recall: 0.8600 - val_loss: 0.3094 - val_recall: 0.8791\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3512 - recall: 0.8575 - val_loss: 0.3093 - val_recall: 0.8791\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3550 - recall: 0.8575 - val_loss: 0.3092 - val_recall: 0.8791\n","Epoch 36/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3462 - recall: 0.8550 - val_loss: 0.3091 - val_recall: 0.8801\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3558 - recall: 0.8553 - val_loss: 0.3091 - val_recall: 0.8811\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3461 - recall: 0.8518 - val_loss: 0.3090 - val_recall: 0.8811\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3464 - recall: 0.8558 - val_loss: 0.3088 - val_recall: 0.8811\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3423 - recall: 0.8563 - val_loss: 0.3088 - val_recall: 0.8811\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3525 - recall: 0.8568 - val_loss: 0.3087 - val_recall: 0.8811\n","Epoch 42/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3452 - recall: 0.8570 - val_loss: 0.3086 - val_recall: 0.8821\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3452 - recall: 0.8565 - val_loss: 0.3085 - val_recall: 0.8821\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3540 - recall: 0.8600 - val_loss: 0.3084 - val_recall: 0.8821\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3533 - recall: 0.8568 - val_loss: 0.3083 - val_recall: 0.8821\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3483 - recall: 0.8575 - val_loss: 0.3082 - val_recall: 0.8821\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3553 - recall: 0.8513 - val_loss: 0.3081 - val_recall: 0.8821\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3484 - recall: 0.8525 - val_loss: 0.3080 - val_recall: 0.8821\n","Epoch 49/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3529 - recall: 0.8558 - val_loss: 0.3079 - val_recall: 0.8821\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3450 - recall: 0.8580 - val_loss: 0.3079 - val_recall: 0.8821\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.32666606960642747\n","test accuracy is:  0.8566286743009026\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D6k8-XYrBei-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"25d9e899-b5df-4f98-beec-44560fa823ca","executionInfo":{"status":"ok","timestamp":1557906608438,"user_tz":-120,"elapsed":6290,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = rmsprop, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3433 - f1: 0.8623 - val_loss: 0.3078 - val_f1: 0.8821\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3521 - f1: 0.8535 - val_loss: 0.3077 - val_f1: 0.8821\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3459 - f1: 0.8548 - val_loss: 0.3076 - val_f1: 0.8821\n","Epoch 4/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3498 - f1: 0.8595 - val_loss: 0.3075 - val_f1: 0.8821\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3456 - f1: 0.8578 - val_loss: 0.3074 - val_f1: 0.8821\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3371 - f1: 0.8550 - val_loss: 0.3074 - val_f1: 0.8821\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3422 - f1: 0.8583 - val_loss: 0.3073 - val_f1: 0.8821\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3385 - f1: 0.8585 - val_loss: 0.3072 - val_f1: 0.8821\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3435 - f1: 0.8578 - val_loss: 0.3072 - val_f1: 0.8821\n","Epoch 10/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3525 - f1: 0.8583 - val_loss: 0.3070 - val_f1: 0.8821\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3470 - f1: 0.8583 - val_loss: 0.3070 - val_f1: 0.8821\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3472 - f1: 0.8548 - val_loss: 0.3069 - val_f1: 0.8821\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3480 - f1: 0.8578 - val_loss: 0.3069 - val_f1: 0.8821\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3447 - f1: 0.8610 - val_loss: 0.3067 - val_f1: 0.8821\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3491 - f1: 0.8560 - val_loss: 0.3067 - val_f1: 0.8821\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3416 - f1: 0.8613 - val_loss: 0.3066 - val_f1: 0.8821\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3449 - f1: 0.8603 - val_loss: 0.3065 - val_f1: 0.8821\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3432 - f1: 0.8598 - val_loss: 0.3065 - val_f1: 0.8821\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3444 - f1: 0.8630 - val_loss: 0.3064 - val_f1: 0.8821\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3458 - f1: 0.8625 - val_loss: 0.3063 - val_f1: 0.8821\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3391 - f1: 0.8640 - val_loss: 0.3062 - val_f1: 0.8821\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3318 - f1: 0.8668 - val_loss: 0.3061 - val_f1: 0.8821\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3414 - f1: 0.8585 - val_loss: 0.3060 - val_f1: 0.8821\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3429 - f1: 0.8615 - val_loss: 0.3060 - val_f1: 0.8821\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3447 - f1: 0.8615 - val_loss: 0.3059 - val_f1: 0.8821\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3455 - f1: 0.8560 - val_loss: 0.3059 - val_f1: 0.8821\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3348 - f1: 0.8613 - val_loss: 0.3058 - val_f1: 0.8821\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3425 - f1: 0.8628 - val_loss: 0.3057 - val_f1: 0.8821\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3381 - f1: 0.8605 - val_loss: 0.3056 - val_f1: 0.8821\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3407 - f1: 0.8660 - val_loss: 0.3056 - val_f1: 0.8821\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3443 - f1: 0.8608 - val_loss: 0.3055 - val_f1: 0.8821\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3494 - f1: 0.8588 - val_loss: 0.3055 - val_f1: 0.8821\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3410 - f1: 0.8588 - val_loss: 0.3054 - val_f1: 0.8821\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3404 - f1: 0.8668 - val_loss: 0.3054 - val_f1: 0.8821\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3454 - f1: 0.8503 - val_loss: 0.3053 - val_f1: 0.8821\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3402 - f1: 0.8588 - val_loss: 0.3052 - val_f1: 0.8821\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3439 - f1: 0.8628 - val_loss: 0.3051 - val_f1: 0.8821\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3371 - f1: 0.8638 - val_loss: 0.3051 - val_f1: 0.8821\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3459 - f1: 0.8575 - val_loss: 0.3050 - val_f1: 0.8821\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3427 - f1: 0.8583 - val_loss: 0.3049 - val_f1: 0.8821\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3436 - f1: 0.8558 - val_loss: 0.3048 - val_f1: 0.8821\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3483 - f1: 0.8600 - val_loss: 0.3047 - val_f1: 0.8831\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3368 - f1: 0.8635 - val_loss: 0.3047 - val_f1: 0.8831\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3399 - f1: 0.8623 - val_loss: 0.3046 - val_f1: 0.8831\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3454 - f1: 0.8593 - val_loss: 0.3045 - val_f1: 0.8831\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3390 - f1: 0.8603 - val_loss: 0.3045 - val_f1: 0.8821\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3419 - f1: 0.8583 - val_loss: 0.3045 - val_f1: 0.8821\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3440 - f1: 0.8568 - val_loss: 0.3044 - val_f1: 0.8821\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3443 - f1: 0.8608 - val_loss: 0.3043 - val_f1: 0.8831\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3408 - f1: 0.8590 - val_loss: 0.3042 - val_f1: 0.8831\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.323787689441396\n","test f1 score is:  0.8578283758884285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_YwnIsPCGbK","colab_type":"code","colab":{}},"source":["adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.25, amsgrad=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zyP0a5RCIgS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"f055ef76-fd9a-443c-fc3b-009d577dfe09","executionInfo":{"status":"ok","timestamp":1557907742092,"user_tz":-120,"elapsed":670912,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2638 - acc: 0.8965 - val_loss: 0.2451 - val_acc: 0.9041\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2360 - acc: 0.9098 - val_loss: 0.2421 - val_acc: 0.9041\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2343 - acc: 0.9095 - val_loss: 0.2408 - val_acc: 0.9051\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2316 - acc: 0.9113 - val_loss: 0.2410 - val_acc: 0.9041\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2259 - acc: 0.9153 - val_loss: 0.2403 - val_acc: 0.9041\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2229 - acc: 0.9145 - val_loss: 0.2401 - val_acc: 0.9041\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2213 - acc: 0.9160 - val_loss: 0.2395 - val_acc: 0.9041\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2227 - acc: 0.9153 - val_loss: 0.2397 - val_acc: 0.9041\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2277 - acc: 0.9185 - val_loss: 0.2392 - val_acc: 0.9051\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2188 - acc: 0.9160 - val_loss: 0.2391 - val_acc: 0.9041\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2209 - acc: 0.9168 - val_loss: 0.2389 - val_acc: 0.9041\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2177 - acc: 0.9168 - val_loss: 0.2391 - val_acc: 0.9041\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2213 - acc: 0.9143 - val_loss: 0.2387 - val_acc: 0.9031\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2146 - acc: 0.9190 - val_loss: 0.2387 - val_acc: 0.9041\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2175 - acc: 0.9143 - val_loss: 0.2386 - val_acc: 0.9041\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2132 - acc: 0.9220 - val_loss: 0.2384 - val_acc: 0.9041\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2124 - acc: 0.9193 - val_loss: 0.2386 - val_acc: 0.9041\n","Epoch 18/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2210 - acc: 0.9158 - val_loss: 0.2383 - val_acc: 0.9051\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2206 - acc: 0.9168 - val_loss: 0.2383 - val_acc: 0.9041\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2194 - acc: 0.9185 - val_loss: 0.2384 - val_acc: 0.9021\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2128 - acc: 0.9213 - val_loss: 0.2383 - val_acc: 0.9021\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2178 - acc: 0.9158 - val_loss: 0.2381 - val_acc: 0.9051\n","Epoch 23/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2124 - acc: 0.9208 - val_loss: 0.2382 - val_acc: 0.9021\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2168 - acc: 0.9135 - val_loss: 0.2381 - val_acc: 0.9021\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2161 - acc: 0.9210 - val_loss: 0.2380 - val_acc: 0.9041\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2095 - acc: 0.9180 - val_loss: 0.2380 - val_acc: 0.9031\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2177 - acc: 0.9155 - val_loss: 0.2379 - val_acc: 0.9041\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2143 - acc: 0.9198 - val_loss: 0.2380 - val_acc: 0.9021\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2150 - acc: 0.9213 - val_loss: 0.2379 - val_acc: 0.9031\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2158 - acc: 0.9193 - val_loss: 0.2378 - val_acc: 0.9041\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2142 - acc: 0.9170 - val_loss: 0.2376 - val_acc: 0.9041\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2139 - acc: 0.9200 - val_loss: 0.2376 - val_acc: 0.9031\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2139 - acc: 0.9180 - val_loss: 0.2376 - val_acc: 0.9031\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2183 - acc: 0.9168 - val_loss: 0.2377 - val_acc: 0.9021\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2070 - acc: 0.9223 - val_loss: 0.2376 - val_acc: 0.9021\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2117 - acc: 0.9195 - val_loss: 0.2376 - val_acc: 0.9031\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2113 - acc: 0.9205 - val_loss: 0.2376 - val_acc: 0.9031\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2122 - acc: 0.9163 - val_loss: 0.2375 - val_acc: 0.9031\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2114 - acc: 0.9200 - val_loss: 0.2375 - val_acc: 0.9031\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2153 - acc: 0.9198 - val_loss: 0.2374 - val_acc: 0.9031\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2109 - acc: 0.9180 - val_loss: 0.2373 - val_acc: 0.9031\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2095 - acc: 0.9183 - val_loss: 0.2373 - val_acc: 0.9031\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2086 - acc: 0.9205 - val_loss: 0.2374 - val_acc: 0.9041\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2107 - acc: 0.9140 - val_loss: 0.2374 - val_acc: 0.9041\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2171 - acc: 0.9210 - val_loss: 0.2374 - val_acc: 0.9031\n","Epoch 46/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2142 - acc: 0.9185 - val_loss: 0.2373 - val_acc: 0.9041\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2078 - acc: 0.9230 - val_loss: 0.2373 - val_acc: 0.9041\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2108 - acc: 0.9205 - val_loss: 0.2374 - val_acc: 0.9041\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2124 - acc: 0.9230 - val_loss: 0.2373 - val_acc: 0.9051\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2118 - acc: 0.9180 - val_loss: 0.2373 - val_acc: 0.9041\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.2677631718790953\n","test accuracy is:  0.8908218356328734\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvmKPMX0CLvh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"3955d1f7-c9c6-4b50-8ea8-39a4ae2a5da0","executionInfo":{"status":"ok","timestamp":1557908413884,"user_tz":-120,"elapsed":1342681,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.2114 - precision: 0.9200 - val_loss: 0.2372 - val_precision: 0.9041\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2113 - precision: 0.9208 - val_loss: 0.2372 - val_precision: 0.9051\n","Epoch 3/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2136 - precision: 0.9180 - val_loss: 0.2372 - val_precision: 0.9051\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2025 - precision: 0.9213 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2053 - precision: 0.9220 - val_loss: 0.2372 - val_precision: 0.9051\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2097 - precision: 0.9215 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2039 - precision: 0.9203 - val_loss: 0.2372 - val_precision: 0.9051\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2055 - precision: 0.9238 - val_loss: 0.2373 - val_precision: 0.9041\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2142 - precision: 0.9223 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2065 - precision: 0.9250 - val_loss: 0.2372 - val_precision: 0.9051\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2077 - precision: 0.9225 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2051 - precision: 0.9213 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2105 - precision: 0.9195 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2140 - precision: 0.9200 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 15/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2077 - precision: 0.9205 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2103 - precision: 0.9155 - val_loss: 0.2371 - val_precision: 0.9041\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2094 - precision: 0.9213 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2073 - precision: 0.9208 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 19/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2064 - precision: 0.9225 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2072 - precision: 0.9178 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 21/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2057 - precision: 0.9198 - val_loss: 0.2371 - val_precision: 0.9051\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2089 - precision: 0.9220 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2102 - precision: 0.9198 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2091 - precision: 0.9220 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2074 - precision: 0.9215 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2095 - precision: 0.9213 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2060 - precision: 0.9233 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2052 - precision: 0.9210 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2094 - precision: 0.9173 - val_loss: 0.2370 - val_precision: 0.9051\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2072 - precision: 0.9200 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2050 - precision: 0.9245 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2097 - precision: 0.9160 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2063 - precision: 0.9205 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2075 - precision: 0.9250 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2066 - precision: 0.9258 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2069 - precision: 0.9200 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2108 - precision: 0.9230 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2044 - precision: 0.9218 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2012 - precision: 0.9238 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2096 - precision: 0.9213 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2107 - precision: 0.9233 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 42/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2047 - precision: 0.9208 - val_loss: 0.2369 - val_precision: 0.9041\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2091 - precision: 0.9190 - val_loss: 0.2369 - val_precision: 0.9041\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2034 - precision: 0.9253 - val_loss: 0.2369 - val_precision: 0.9041\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2000 - precision: 0.9250 - val_loss: 0.2369 - val_precision: 0.9051\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2033 - precision: 0.9205 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2046 - precision: 0.9233 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2066 - precision: 0.9245 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2076 - precision: 0.9208 - val_loss: 0.2368 - val_precision: 0.9051\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2099 - precision: 0.9218 - val_loss: 0.2368 - val_precision: 0.9051\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.26865245488119754\n","test accuracy is:  0.8938212357528494\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j8bCidAoCQ6m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"32c73aa7-4463-4342-8726-e4309a1756a0","executionInfo":{"status":"ok","timestamp":1557909086290,"user_tz":-120,"elapsed":2015064,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 18s 4ms/step - loss: 0.2045 - recall: 0.9213 - val_loss: 0.2368 - val_recall: 0.9051\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2088 - recall: 0.9230 - val_loss: 0.2368 - val_recall: 0.9051\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2022 - recall: 0.9258 - val_loss: 0.2368 - val_recall: 0.9051\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2089 - recall: 0.9180 - val_loss: 0.2368 - val_recall: 0.9051\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2055 - recall: 0.9180 - val_loss: 0.2368 - val_recall: 0.9051\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2076 - recall: 0.9200 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2035 - recall: 0.9213 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2064 - recall: 0.9220 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 9/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2036 - recall: 0.9253 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2056 - recall: 0.9248 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2072 - recall: 0.9220 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2029 - recall: 0.9233 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2031 - recall: 0.9250 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2069 - recall: 0.9228 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 15/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.2060 - recall: 0.9243 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2001 - recall: 0.9210 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2056 - recall: 0.9235 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2022 - recall: 0.9245 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2013 - recall: 0.9235 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2081 - recall: 0.9223 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2071 - recall: 0.9210 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2043 - recall: 0.9240 - val_loss: 0.2367 - val_recall: 0.9051\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2027 - recall: 0.9213 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2050 - recall: 0.9245 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2030 - recall: 0.9238 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2033 - recall: 0.9235 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1955 - recall: 0.9213 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2045 - recall: 0.9250 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1973 - recall: 0.9235 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1993 - recall: 0.9225 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2022 - recall: 0.9215 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 32/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2086 - recall: 0.9210 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2069 - recall: 0.9208 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2042 - recall: 0.9228 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2069 - recall: 0.9210 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2077 - recall: 0.9233 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2047 - recall: 0.9228 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 38/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.1996 - recall: 0.9230 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2072 - recall: 0.9235 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2018 - recall: 0.9200 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2041 - recall: 0.9250 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2068 - recall: 0.9180 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 43/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2019 - recall: 0.9215 - val_loss: 0.2365 - val_recall: 0.9051\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2045 - recall: 0.9230 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1988 - recall: 0.9195 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2065 - recall: 0.9255 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2055 - recall: 0.9240 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2014 - recall: 0.9188 - val_loss: 0.2365 - val_recall: 0.9051\n","Epoch 49/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2040 - recall: 0.9185 - val_loss: 0.2366 - val_recall: 0.9051\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1980 - recall: 0.9285 - val_loss: 0.2366 - val_recall: 0.9051\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.26872998329206865\n","test accuracy is:  0.8938212357528494\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NZj3JXGOCWLM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"5f187628-416a-473b-d4cb-8fcd9fadf69a","executionInfo":{"status":"ok","timestamp":1557909778695,"user_tz":-120,"elapsed":2707447,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = adam, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 17s 4ms/step - loss: 0.2055 - f1: 0.9220 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2018 - f1: 0.9215 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2030 - f1: 0.9263 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 4/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2061 - f1: 0.9180 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2028 - f1: 0.9203 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1986 - f1: 0.9208 - val_loss: 0.2367 - val_f1: 0.9051\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2003 - f1: 0.9235 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2058 - f1: 0.9223 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2018 - f1: 0.9250 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1950 - f1: 0.9210 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 11/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.1919 - f1: 0.9295 - val_loss: 0.2367 - val_f1: 0.9051\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2065 - f1: 0.9230 - val_loss: 0.2367 - val_f1: 0.9051\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2059 - f1: 0.9208 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2011 - f1: 0.9225 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2040 - f1: 0.9235 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2035 - f1: 0.9210 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2030 - f1: 0.9238 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2042 - f1: 0.9215 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2003 - f1: 0.9273 - val_loss: 0.2366 - val_f1: 0.9041\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2019 - f1: 0.9220 - val_loss: 0.2366 - val_f1: 0.9041\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2074 - f1: 0.9230 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2010 - f1: 0.9243 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2014 - f1: 0.9238 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2022 - f1: 0.9240 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2015 - f1: 0.9218 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2023 - f1: 0.9210 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 27/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1980 - f1: 0.9230 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2021 - f1: 0.9265 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2013 - f1: 0.9255 - val_loss: 0.2366 - val_f1: 0.9041\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1977 - f1: 0.9280 - val_loss: 0.2366 - val_f1: 0.9051\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2052 - f1: 0.9228 - val_loss: 0.2366 - val_f1: 0.9041\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2033 - f1: 0.9225 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2014 - f1: 0.9245 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.1991 - f1: 0.9245 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2056 - f1: 0.9218 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2022 - f1: 0.9248 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2017 - f1: 0.9215 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1998 - f1: 0.9218 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.1975 - f1: 0.9248 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2032 - f1: 0.9260 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2033 - f1: 0.9245 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2067 - f1: 0.9208 - val_loss: 0.2365 - val_f1: 0.9031\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2061 - f1: 0.9225 - val_loss: 0.2365 - val_f1: 0.9051\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2005 - f1: 0.9243 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2021 - f1: 0.9238 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2070 - f1: 0.9248 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.2004 - f1: 0.9220 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2028 - f1: 0.9250 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.2065 - f1: 0.9220 - val_loss: 0.2365 - val_f1: 0.9041\n","Epoch 50/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.2021 - f1: 0.9210 - val_loss: 0.2365 - val_f1: 0.9041\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.26885231355809674\n","test f1 score is:  0.893821177399652\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ROb4THFPCeDJ","colab_type":"code","colab":{}},"source":["model.save_weights('/content/drive/My Drive/Sarcasm Detection/Plots/LSTM_optimized_Weights.h5')"],"execution_count":0,"outputs":[]}]}