{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of LSTM_CNN.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"haXfHHQJIfXR","colab_type":"code","outputId":"6ca34cf3-57c8-4ef5-e121-2080b577ba56","executionInfo":{"status":"ok","timestamp":1557929478077,"user_tz":-120,"elapsed":2410,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"WoANn0IpIo-K","colab_type":"code","outputId":"6c608f68-8c35-4d46-97ad-6dc39b9f153d","executionInfo":{"status":"ok","timestamp":1557929481225,"user_tz":-120,"elapsed":5535,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2BhJGRlbItt9","colab_type":"code","outputId":"328f94c2-c810-4f0a-970f-7f95621a9b62","executionInfo":{"status":"ok","timestamp":1557929481228,"user_tz":-120,"elapsed":5515,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":198}},"source":["import pandas as pd\n","Data =  pd.read_json('/content/drive/My Drive/Sarcasm Detection/Arabic News Headlines Dataset.json', orient = 'split')\n","Data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>topic</th>\n","      <th>length</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...</td>\n","      <td>Society</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...</td>\n","      <td>Sports</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...</td>\n","      <td>Misc</td>\n","      <td>17</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...</td>\n","      <td>None</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...</td>\n","      <td>Misc</td>\n","      <td>12</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           headlines  ... is_sarcastic\n","0  طالب يصبح متعلّماً بعد دراسته وحدة عن القائد ف...  ...            1\n","1  سموحة يقلص الفارق ويسجل هدفا ثانيا في شباك الم...  ...            0\n","2  ليتها الحدود – الولايات المتحدة تهدد بفرض عقوب...  ...            1\n","3  وزيرة الهجرة تتواصل مع سفير مصر في نيوزيلندا ل...  ...            0\n","4  ليتها الحدود – مصر تقرر إرسال أعضاء السائح الب...  ...            1\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"eZfh50WcKc8j","colab_type":"code","colab":{}},"source":["X = Data['headlines']\n","Labels = Data['is_sarcastic']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGE1RQHEK5KP","colab_type":"code","outputId":"38efff9e-a25c-4efa-8e89-7ac92791bbb8","executionInfo":{"status":"ok","timestamp":1557929481233,"user_tz":-120,"elapsed":5499,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","max_sequence_length = np.max(Data['length'])\n","print(\"max length is:\", max_sequence_length)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["max length is: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pIh6s6cxJB02","colab_type":"code","outputId":"db1523be-c39a-48dc-8716-51f76c9b4174","executionInfo":{"status":"ok","timestamp":1557929481237,"user_tz":-120,"elapsed":5485,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import keras\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=30000)\n","tokenizer.fit_on_texts(X)\n","sequences = tokenizer.texts_to_sequences(X)\n","\n","word_index = tokenizer.word_index   # a dictionary of each word and its index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 20595 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"enlqxEX4KZY0","colab_type":"code","outputId":"5890abb8-c1f2-4483-d983-56ab72f9e44d","executionInfo":{"status":"ok","timestamp":1557929481238,"user_tz":-120,"elapsed":5467,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.preprocessing.sequence import pad_sequences\n","data = pad_sequences(sequences, maxlen=max_sequence_length)\n","print('Shape of data tensor:', data.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Shape of data tensor: (6669, 34)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dYo4nQrLVVj","colab_type":"code","outputId":"cbbc31cd-8d6a-46f1-825a-b3ffef1cb187","executionInfo":{"status":"ok","timestamp":1557929481240,"user_tz":-120,"elapsed":5455,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from keras.utils import to_categorical\n","labels = to_categorical(np.asarray(Labels))  ## one hot of the output\n","print('Shape of label tensor:', labels.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (6669, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4r21pAbOLz0w","colab_type":"code","colab":{}},"source":["import pickle as p\n","fastText = p.load(open('/content/drive/My Drive/Sarcasm Detection/FastText_Wiki_Embeddings.p', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxwadMk9MHir","colab_type":"code","outputId":"8219dd2e-bffa-4f05-f144-96d75103528d","executionInfo":{"status":"ok","timestamp":1557929484830,"user_tz":-120,"elapsed":9022,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# prepare embedding matrix  (matrix of embeddings of the words in our dataset)\n","num_words = len(word_index) + 1\n","# initialize the np array\n","unKnown = list()\n","embedding_matrix = np.zeros((num_words, 300))\n","l=0\n","# find the embeddings from the pre trained embedding matrix of fast text wiki\n","for word, i in word_index.items():\n","    embedding_vector = fastText.get(word)\n","    if embedding_vector is not None:\n","        l+=1\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","      unKnown.append(word)\n","print(\"the number of words found in fast text embeddings =\", l)\n","print(\"the number of words not found in fast text embeddings =\", 20595- l)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["the number of words found in fast text embeddings = 17289\n","the number of words not found in fast text embeddings = 3306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpFKygkfMdYG","colab_type":"code","colab":{}},"source":["from keras.initializers import Constant\n","from keras.layers import Input, Embedding, Conv2D, GlobalMaxPooling2D, Dense, Dropout, LSTM\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahqU4hM6Mj1F","colab_type":"code","colab":{}},"source":["# shuffle the data\n","\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","## split the data into training, testing\n","\n","nb_validation_samples = int(0.25* data.shape[0])\n","\n","x_train = data[:-nb_validation_samples]\n","y_train = labels[:-nb_validation_samples]\n","x_test = data[-nb_validation_samples:]\n","y_test = labels[-nb_validation_samples:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7FbLoXSM5O7","colab_type":"code","colab":{}},"source":["embedding_layer = Embedding(num_words,\n","                            300,\n","                            embeddings_initializer=Constant(embedding_matrix),\n","                            input_length=max_sequence_length,\n","                            trainable=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVPVJUeoNNJv","colab_type":"code","colab":{}},"source":["# the model\n","\n","sequence_input = Input(shape=(max_sequence_length,), dtype='int32')             ## input layer\n","embedded_sequences = embedding_layer(sequence_input)                            ## embeddings layer\n","X = LSTM(128, return_sequences=True)(embedded_sequences)\n","X = Dropout(0.5)(X)\n","X = LSTM(128, return_sequences=True)(X)\n","X = Dropout(0.5)(X)\n","X = keras.layers.core.Reshape((34,128,1))(X)\n","x1 = Conv2D(2, (2, 100), activation='relu')(X)                 ## conv 1\n","x1 = GlobalMaxPooling2D()(x1)                                                   ## max 1\n","x2 = Conv2D(2, (3, 100), activation='relu')(X)                 ## conv 2\n","x2 = GlobalMaxPooling2D()(x2)                                                   ## max 2\n","x3 = Conv2D(2, (4, 100), activation='relu')(X)                 ## conv 3\n","x3 = GlobalMaxPooling2D()(x3)                                                   ## max 3\n","x  = keras.layers.concatenate([x1, x2, x3])                                     ## concatenate\n","preds = Dense(2, activation='softmax')(x)                                       ## softmax layer\n","\n","model = Model(sequence_input, preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsWFiq6Y1Boc","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","\n","def recall(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","\n","      \n","def precision(y_true, y_pred):\n","        \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","      \n","\n","def f1(y_true, y_pred):\n","    \n","    Precision = precision(y_true, y_pred)\n","    Recall = recall(y_true, y_pred)\n","    f1 = 2*((Precision*Recall)/(Precision+Recall+K.epsilon()))\n","    \n","    return f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Q11ld4l08xB","colab_type":"code","colab":{}},"source":["adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.3, amsgrad=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dwOp9x61NhB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"bdef78cc-92d7-4cda-af2a-0c3e39c4caa7","executionInfo":{"status":"ok","timestamp":1557930483394,"user_tz":-120,"elapsed":4698,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = ['acc'])\n","\n","model.fit(x_train, y_train, \n","          validation_split = 0.2, \n","          batch_size = 32, \n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', accuracy)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.6669 - acc: 0.6363 - val_loss: 0.6264 - val_acc: 0.7383\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.6234 - acc: 0.7283 - val_loss: 0.5795 - val_acc: 0.7772\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.5859 - acc: 0.7641 - val_loss: 0.5393 - val_acc: 0.8122\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.5558 - acc: 0.7758 - val_loss: 0.5055 - val_acc: 0.8202\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.5284 - acc: 0.7856 - val_loss: 0.4795 - val_acc: 0.8272\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.5049 - acc: 0.8043 - val_loss: 0.4580 - val_acc: 0.8272\n","Epoch 7/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.4901 - acc: 0.7973 - val_loss: 0.4410 - val_acc: 0.8312\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4743 - acc: 0.8028 - val_loss: 0.4272 - val_acc: 0.8322\n","Epoch 9/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.4630 - acc: 0.8078 - val_loss: 0.4167 - val_acc: 0.8352\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4515 - acc: 0.8155 - val_loss: 0.4084 - val_acc: 0.8362\n","Epoch 11/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4452 - acc: 0.8095 - val_loss: 0.4017 - val_acc: 0.8352\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4396 - acc: 0.8145 - val_loss: 0.3960 - val_acc: 0.8382\n","Epoch 13/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.4356 - acc: 0.8110 - val_loss: 0.3911 - val_acc: 0.8342\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4273 - acc: 0.8125 - val_loss: 0.3870 - val_acc: 0.8332\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4261 - acc: 0.8150 - val_loss: 0.3833 - val_acc: 0.8322\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4200 - acc: 0.8158 - val_loss: 0.3801 - val_acc: 0.8342\n","Epoch 17/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4157 - acc: 0.8175 - val_loss: 0.3775 - val_acc: 0.8362\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4103 - acc: 0.8203 - val_loss: 0.3750 - val_acc: 0.8392\n","Epoch 19/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.4071 - acc: 0.8238 - val_loss: 0.3728 - val_acc: 0.8392\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4086 - acc: 0.8150 - val_loss: 0.3708 - val_acc: 0.8402\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4069 - acc: 0.8225 - val_loss: 0.3689 - val_acc: 0.8412\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.4002 - acc: 0.8260 - val_loss: 0.3672 - val_acc: 0.8412\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3992 - acc: 0.8193 - val_loss: 0.3655 - val_acc: 0.8392\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3988 - acc: 0.8238 - val_loss: 0.3642 - val_acc: 0.8382\n","Epoch 25/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.4014 - acc: 0.8200 - val_loss: 0.3630 - val_acc: 0.8412\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3931 - acc: 0.8275 - val_loss: 0.3617 - val_acc: 0.8402\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3912 - acc: 0.8288 - val_loss: 0.3604 - val_acc: 0.8412\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3880 - acc: 0.8280 - val_loss: 0.3594 - val_acc: 0.8412\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3897 - acc: 0.8250 - val_loss: 0.3586 - val_acc: 0.8412\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3850 - acc: 0.8310 - val_loss: 0.3578 - val_acc: 0.8432\n","Epoch 31/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3850 - acc: 0.8295 - val_loss: 0.3567 - val_acc: 0.8422\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3845 - acc: 0.8260 - val_loss: 0.3560 - val_acc: 0.8402\n","Epoch 33/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3845 - acc: 0.8298 - val_loss: 0.3552 - val_acc: 0.8412\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3843 - acc: 0.8295 - val_loss: 0.3544 - val_acc: 0.8442\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3830 - acc: 0.8290 - val_loss: 0.3537 - val_acc: 0.8452\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3819 - acc: 0.8333 - val_loss: 0.3530 - val_acc: 0.8452\n","Epoch 37/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3806 - acc: 0.8338 - val_loss: 0.3524 - val_acc: 0.8462\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3816 - acc: 0.8303 - val_loss: 0.3518 - val_acc: 0.8482\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3806 - acc: 0.8258 - val_loss: 0.3514 - val_acc: 0.8472\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3788 - acc: 0.8300 - val_loss: 0.3509 - val_acc: 0.8472\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3759 - acc: 0.8305 - val_loss: 0.3504 - val_acc: 0.8482\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3781 - acc: 0.8355 - val_loss: 0.3499 - val_acc: 0.8492\n","Epoch 43/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3784 - acc: 0.8345 - val_loss: 0.3494 - val_acc: 0.8501\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3755 - acc: 0.8363 - val_loss: 0.3490 - val_acc: 0.8501\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3739 - acc: 0.8330 - val_loss: 0.3486 - val_acc: 0.8501\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3725 - acc: 0.8400 - val_loss: 0.3482 - val_acc: 0.8501\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3716 - acc: 0.8288 - val_loss: 0.3478 - val_acc: 0.8501\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3710 - acc: 0.8360 - val_loss: 0.3474 - val_acc: 0.8511\n","Epoch 49/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3719 - acc: 0.8330 - val_loss: 0.3471 - val_acc: 0.8511\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3697 - acc: 0.8405 - val_loss: 0.3467 - val_acc: 0.8511\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.3494331889261224\n","test accuracy is:  0.8380323935570514\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHG3jG5E03ue","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"12619af7-0a9f-4847-85e5-5b9a8f94931d","executionInfo":{"status":"ok","timestamp":1557931177012,"user_tz":-120,"elapsed":13987,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [precision])\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, prec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', prec)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 16s 4ms/step - loss: 0.3703 - precision: 0.8338 - val_loss: 0.3451 - val_precision: 0.8521\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3659 - precision: 0.8353 - val_loss: 0.3442 - val_precision: 0.8521\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3653 - precision: 0.8390 - val_loss: 0.3436 - val_precision: 0.8521\n","Epoch 4/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3649 - precision: 0.8383 - val_loss: 0.3432 - val_precision: 0.8531\n","Epoch 5/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3672 - precision: 0.8390 - val_loss: 0.3427 - val_precision: 0.8531\n","Epoch 6/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3604 - precision: 0.8388 - val_loss: 0.3423 - val_precision: 0.8541\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3653 - precision: 0.8383 - val_loss: 0.3419 - val_precision: 0.8541\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3629 - precision: 0.8358 - val_loss: 0.3416 - val_precision: 0.8541\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3593 - precision: 0.8393 - val_loss: 0.3412 - val_precision: 0.8551\n","Epoch 10/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3589 - precision: 0.8398 - val_loss: 0.3409 - val_precision: 0.8551\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3609 - precision: 0.8375 - val_loss: 0.3406 - val_precision: 0.8561\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3607 - precision: 0.8408 - val_loss: 0.3403 - val_precision: 0.8571\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3580 - precision: 0.8388 - val_loss: 0.3400 - val_precision: 0.8571\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3582 - precision: 0.8448 - val_loss: 0.3397 - val_precision: 0.8571\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3596 - precision: 0.8395 - val_loss: 0.3395 - val_precision: 0.8571\n","Epoch 16/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3584 - precision: 0.8425 - val_loss: 0.3393 - val_precision: 0.8581\n","Epoch 17/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3595 - precision: 0.8423 - val_loss: 0.3390 - val_precision: 0.8601\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3536 - precision: 0.8425 - val_loss: 0.3388 - val_precision: 0.8591\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3537 - precision: 0.8398 - val_loss: 0.3386 - val_precision: 0.8601\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3588 - precision: 0.8380 - val_loss: 0.3384 - val_precision: 0.8611\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3569 - precision: 0.8408 - val_loss: 0.3383 - val_precision: 0.8611\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3554 - precision: 0.8398 - val_loss: 0.3381 - val_precision: 0.8611\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3525 - precision: 0.8413 - val_loss: 0.3379 - val_precision: 0.8611\n","Epoch 24/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3551 - precision: 0.8428 - val_loss: 0.3377 - val_precision: 0.8621\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3561 - precision: 0.8425 - val_loss: 0.3375 - val_precision: 0.8621\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3540 - precision: 0.8433 - val_loss: 0.3373 - val_precision: 0.8621\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3576 - precision: 0.8405 - val_loss: 0.3372 - val_precision: 0.8621\n","Epoch 28/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3550 - precision: 0.8430 - val_loss: 0.3370 - val_precision: 0.8621\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3556 - precision: 0.8440 - val_loss: 0.3369 - val_precision: 0.8621\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3534 - precision: 0.8445 - val_loss: 0.3367 - val_precision: 0.8621\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3539 - precision: 0.8448 - val_loss: 0.3366 - val_precision: 0.8611\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3542 - precision: 0.8413 - val_loss: 0.3364 - val_precision: 0.8621\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3495 - precision: 0.8463 - val_loss: 0.3363 - val_precision: 0.8621\n","Epoch 34/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3537 - precision: 0.8415 - val_loss: 0.3362 - val_precision: 0.8621\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3525 - precision: 0.8428 - val_loss: 0.3360 - val_precision: 0.8621\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3533 - precision: 0.8440 - val_loss: 0.3359 - val_precision: 0.8621\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3527 - precision: 0.8408 - val_loss: 0.3357 - val_precision: 0.8621\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3533 - precision: 0.8438 - val_loss: 0.3356 - val_precision: 0.8621\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3466 - precision: 0.8483 - val_loss: 0.3355 - val_precision: 0.8621\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3527 - precision: 0.8468 - val_loss: 0.3353 - val_precision: 0.8621\n","Epoch 41/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3502 - precision: 0.8448 - val_loss: 0.3352 - val_precision: 0.8621\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3512 - precision: 0.8435 - val_loss: 0.3351 - val_precision: 0.8621\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3512 - precision: 0.8448 - val_loss: 0.3350 - val_precision: 0.8621\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3501 - precision: 0.8465 - val_loss: 0.3348 - val_precision: 0.8621\n","Epoch 45/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3486 - precision: 0.8460 - val_loss: 0.3347 - val_precision: 0.8621\n","Epoch 46/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3504 - precision: 0.8495 - val_loss: 0.3346 - val_precision: 0.8621\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3463 - precision: 0.8433 - val_loss: 0.3345 - val_precision: 0.8621\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3495 - precision: 0.8478 - val_loss: 0.3344 - val_precision: 0.8611\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3471 - precision: 0.8480 - val_loss: 0.3343 - val_precision: 0.8611\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3480 - precision: 0.8463 - val_loss: 0.3341 - val_precision: 0.8611\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.334810690209046\n","test accuracy is:  0.8428314337311351\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nk60ozLH0yVV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"fe3cb7f3-09cf-4545-8290-ac8f884c2360","executionInfo":{"status":"ok","timestamp":1557931864040,"user_tz":-120,"elapsed":670782,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","              optimizer = adam,\n","              metrics = [recall])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, rec = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test accuracy is: ', rec)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3480 - recall: 0.8493 - val_loss: 0.3336 - val_recall: 0.8601\n","Epoch 2/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3494 - recall: 0.8435 - val_loss: 0.3333 - val_recall: 0.8611\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3471 - recall: 0.8470 - val_loss: 0.3332 - val_recall: 0.8611\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3447 - recall: 0.8498 - val_loss: 0.3330 - val_recall: 0.8611\n","Epoch 5/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3449 - recall: 0.8485 - val_loss: 0.3328 - val_recall: 0.8611\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3523 - recall: 0.8438 - val_loss: 0.3326 - val_recall: 0.8611\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3439 - recall: 0.8433 - val_loss: 0.3325 - val_recall: 0.8601\n","Epoch 8/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3455 - recall: 0.8445 - val_loss: 0.3324 - val_recall: 0.8601\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3440 - recall: 0.8493 - val_loss: 0.3323 - val_recall: 0.8601\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3440 - recall: 0.8488 - val_loss: 0.3321 - val_recall: 0.8601\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3435 - recall: 0.8475 - val_loss: 0.3320 - val_recall: 0.8601\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3452 - recall: 0.8445 - val_loss: 0.3319 - val_recall: 0.8601\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3443 - recall: 0.8453 - val_loss: 0.3318 - val_recall: 0.8601\n","Epoch 14/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3456 - recall: 0.8420 - val_loss: 0.3317 - val_recall: 0.8601\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3464 - recall: 0.8505 - val_loss: 0.3316 - val_recall: 0.8601\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3487 - recall: 0.8483 - val_loss: 0.3315 - val_recall: 0.8601\n","Epoch 17/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3444 - recall: 0.8463 - val_loss: 0.3314 - val_recall: 0.8601\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3442 - recall: 0.8478 - val_loss: 0.3313 - val_recall: 0.8601\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3442 - recall: 0.8485 - val_loss: 0.3312 - val_recall: 0.8611\n","Epoch 20/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3433 - recall: 0.8468 - val_loss: 0.3312 - val_recall: 0.8611\n","Epoch 21/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3446 - recall: 0.8485 - val_loss: 0.3311 - val_recall: 0.8611\n","Epoch 22/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3450 - recall: 0.8500 - val_loss: 0.3310 - val_recall: 0.8611\n","Epoch 23/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3386 - recall: 0.8520 - val_loss: 0.3309 - val_recall: 0.8601\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3442 - recall: 0.8470 - val_loss: 0.3308 - val_recall: 0.8601\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3405 - recall: 0.8508 - val_loss: 0.3307 - val_recall: 0.8611\n","Epoch 26/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3430 - recall: 0.8448 - val_loss: 0.3306 - val_recall: 0.8611\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3387 - recall: 0.8548 - val_loss: 0.3305 - val_recall: 0.8611\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3423 - recall: 0.8495 - val_loss: 0.3305 - val_recall: 0.8611\n","Epoch 29/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3418 - recall: 0.8488 - val_loss: 0.3304 - val_recall: 0.8611\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3433 - recall: 0.8528 - val_loss: 0.3303 - val_recall: 0.8611\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3449 - recall: 0.8500 - val_loss: 0.3302 - val_recall: 0.8611\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3401 - recall: 0.8503 - val_loss: 0.3302 - val_recall: 0.8611\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3412 - recall: 0.8468 - val_loss: 0.3301 - val_recall: 0.8611\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3390 - recall: 0.8498 - val_loss: 0.3300 - val_recall: 0.8611\n","Epoch 35/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3445 - recall: 0.8495 - val_loss: 0.3299 - val_recall: 0.8611\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3412 - recall: 0.8475 - val_loss: 0.3299 - val_recall: 0.8611\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3385 - recall: 0.8510 - val_loss: 0.3298 - val_recall: 0.8611\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3406 - recall: 0.8485 - val_loss: 0.3297 - val_recall: 0.8601\n","Epoch 39/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3428 - recall: 0.8488 - val_loss: 0.3296 - val_recall: 0.8601\n","Epoch 40/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3421 - recall: 0.8483 - val_loss: 0.3296 - val_recall: 0.8611\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3405 - recall: 0.8508 - val_loss: 0.3295 - val_recall: 0.8601\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3416 - recall: 0.8460 - val_loss: 0.3294 - val_recall: 0.8611\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3399 - recall: 0.8503 - val_loss: 0.3294 - val_recall: 0.8611\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3439 - recall: 0.8438 - val_loss: 0.3293 - val_recall: 0.8611\n","Epoch 45/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3437 - recall: 0.8510 - val_loss: 0.3292 - val_recall: 0.8601\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3362 - recall: 0.8520 - val_loss: 0.3292 - val_recall: 0.8601\n","Epoch 47/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3391 - recall: 0.8488 - val_loss: 0.3291 - val_recall: 0.8601\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3421 - recall: 0.8433 - val_loss: 0.3290 - val_recall: 0.8611\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3377 - recall: 0.8500 - val_loss: 0.3290 - val_recall: 0.8611\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3356 - recall: 0.8510 - val_loss: 0.3289 - val_recall: 0.8611\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.3278551448156681\n","test accuracy is:  0.8476304739409746\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IEr6UNQq0t1T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1908},"outputId":"9457acb6-94ce-4f93-c5b8-e0a4f27a5d56","executionInfo":{"status":"ok","timestamp":1557932541970,"user_tz":-120,"elapsed":667369,"user":{"displayName":"Pasant Amin","photoUrl":"","userId":"15011853940927982234"}}},"source":["model.compile(loss = 'categorical_crossentropy',\n","          optimizer = adam, \n","          metrics = [f1])\n","\n","model.fit(x_train, y_train,\n","          validation_split = 0.2,\n","          batch_size = 32,\n","          epochs = 50)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('test loss is:', loss)\n","print('test f1 score is: ', accuracy)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Train on 4001 samples, validate on 1001 samples\n","Epoch 1/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3376 - f1: 0.8515 - val_loss: 0.3287 - val_f1: 0.8611\n","Epoch 2/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3359 - f1: 0.8525 - val_loss: 0.3285 - val_f1: 0.8601\n","Epoch 3/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3421 - f1: 0.8423 - val_loss: 0.3284 - val_f1: 0.8601\n","Epoch 4/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3373 - f1: 0.8503 - val_loss: 0.3283 - val_f1: 0.8611\n","Epoch 5/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3371 - f1: 0.8520 - val_loss: 0.3282 - val_f1: 0.8611\n","Epoch 6/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3390 - f1: 0.8523 - val_loss: 0.3281 - val_f1: 0.8611\n","Epoch 7/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3377 - f1: 0.8490 - val_loss: 0.3280 - val_f1: 0.8611\n","Epoch 8/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3410 - f1: 0.8508 - val_loss: 0.3280 - val_f1: 0.8611\n","Epoch 9/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3345 - f1: 0.8528 - val_loss: 0.3279 - val_f1: 0.8611\n","Epoch 10/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3373 - f1: 0.8500 - val_loss: 0.3278 - val_f1: 0.8611\n","Epoch 11/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3407 - f1: 0.8475 - val_loss: 0.3278 - val_f1: 0.8611\n","Epoch 12/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3401 - f1: 0.8518 - val_loss: 0.3277 - val_f1: 0.8611\n","Epoch 13/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3348 - f1: 0.8528 - val_loss: 0.3276 - val_f1: 0.8611\n","Epoch 14/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3336 - f1: 0.8575 - val_loss: 0.3276 - val_f1: 0.8611\n","Epoch 15/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3365 - f1: 0.8540 - val_loss: 0.3275 - val_f1: 0.8611\n","Epoch 16/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3343 - f1: 0.8550 - val_loss: 0.3274 - val_f1: 0.8611\n","Epoch 17/50\n","4001/4001 [==============================] - 15s 4ms/step - loss: 0.3327 - f1: 0.8528 - val_loss: 0.3274 - val_f1: 0.8611\n","Epoch 18/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3349 - f1: 0.8508 - val_loss: 0.3273 - val_f1: 0.8611\n","Epoch 19/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3354 - f1: 0.8503 - val_loss: 0.3273 - val_f1: 0.8611\n","Epoch 20/50\n","4001/4001 [==============================] - 14s 4ms/step - loss: 0.3341 - f1: 0.8563 - val_loss: 0.3272 - val_f1: 0.8621\n","Epoch 21/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3381 - f1: 0.8520 - val_loss: 0.3272 - val_f1: 0.8611\n","Epoch 22/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3361 - f1: 0.8465 - val_loss: 0.3271 - val_f1: 0.8621\n","Epoch 23/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3359 - f1: 0.8465 - val_loss: 0.3271 - val_f1: 0.8621\n","Epoch 24/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3326 - f1: 0.8528 - val_loss: 0.3270 - val_f1: 0.8621\n","Epoch 25/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3319 - f1: 0.8565 - val_loss: 0.3270 - val_f1: 0.8621\n","Epoch 26/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3352 - f1: 0.8578 - val_loss: 0.3269 - val_f1: 0.8621\n","Epoch 27/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3346 - f1: 0.8533 - val_loss: 0.3269 - val_f1: 0.8621\n","Epoch 28/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3338 - f1: 0.8548 - val_loss: 0.3268 - val_f1: 0.8621\n","Epoch 29/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3368 - f1: 0.8468 - val_loss: 0.3268 - val_f1: 0.8621\n","Epoch 30/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3357 - f1: 0.8528 - val_loss: 0.3267 - val_f1: 0.8621\n","Epoch 31/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3354 - f1: 0.8498 - val_loss: 0.3267 - val_f1: 0.8621\n","Epoch 32/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3352 - f1: 0.8523 - val_loss: 0.3266 - val_f1: 0.8621\n","Epoch 33/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3329 - f1: 0.8523 - val_loss: 0.3266 - val_f1: 0.8621\n","Epoch 34/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3350 - f1: 0.8530 - val_loss: 0.3265 - val_f1: 0.8621\n","Epoch 35/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3319 - f1: 0.8573 - val_loss: 0.3265 - val_f1: 0.8631\n","Epoch 36/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3334 - f1: 0.8543 - val_loss: 0.3264 - val_f1: 0.8641\n","Epoch 37/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3330 - f1: 0.8518 - val_loss: 0.3264 - val_f1: 0.8631\n","Epoch 38/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3328 - f1: 0.8548 - val_loss: 0.3263 - val_f1: 0.8631\n","Epoch 39/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3299 - f1: 0.8558 - val_loss: 0.3263 - val_f1: 0.8631\n","Epoch 40/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3331 - f1: 0.8543 - val_loss: 0.3263 - val_f1: 0.8631\n","Epoch 41/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3324 - f1: 0.8503 - val_loss: 0.3262 - val_f1: 0.8631\n","Epoch 42/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3316 - f1: 0.8548 - val_loss: 0.3262 - val_f1: 0.8631\n","Epoch 43/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3308 - f1: 0.8538 - val_loss: 0.3261 - val_f1: 0.8631\n","Epoch 44/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3321 - f1: 0.8570 - val_loss: 0.3261 - val_f1: 0.8631\n","Epoch 45/50\n","4001/4001 [==============================] - 14s 3ms/step - loss: 0.3287 - f1: 0.8598 - val_loss: 0.3260 - val_f1: 0.8631\n","Epoch 46/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3298 - f1: 0.8555 - val_loss: 0.3260 - val_f1: 0.8641\n","Epoch 47/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3277 - f1: 0.8570 - val_loss: 0.3260 - val_f1: 0.8641\n","Epoch 48/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3329 - f1: 0.8520 - val_loss: 0.3259 - val_f1: 0.8651\n","Epoch 49/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3332 - f1: 0.8533 - val_loss: 0.3259 - val_f1: 0.8651\n","Epoch 50/50\n","4001/4001 [==============================] - 13s 3ms/step - loss: 0.3309 - f1: 0.8543 - val_loss: 0.3258 - val_f1: 0.8651\n","1667/1667 [==============================] - 2s 1ms/step\n","test loss is: 0.3236843875123844\n","test f1 score is:  0.8494300544083154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lz9NTzDpF-S0","colab_type":"code","colab":{}},"source":[" model.save_weights('/content/drive/My Drive/Sarcasm Detection/Plots/LSTM_CNN_optimized_Weights.h5')"],"execution_count":0,"outputs":[]}]}